Training Iteration 1: Minibatch Loss: 0.129155
Training Iteration 2: Minibatch Loss: 0.093688
Training Iteration 3: Minibatch Loss: 0.083777
Training Iteration 4: Minibatch Loss: 0.076989
Training Iteration 5: Minibatch Loss: 0.073781
Training Iteration 6: Minibatch Loss: 0.071118
Training Iteration 7: Minibatch Loss: 0.068402
Training Iteration 8: Minibatch Loss: 0.068864
Training Iteration 9: Minibatch Loss: 0.068567
Training Iteration 10: Minibatch Loss: 0.065918
Training Iteration 11: Minibatch Loss: 0.065300
Training Iteration 12: Minibatch Loss: 0.065412
Training Iteration 13: Minibatch Loss: 0.061093
Training Iteration 14: Minibatch Loss: 0.062041
Training Iteration 15: Minibatch Loss: 0.057985
Training Iteration 16: Minibatch Loss: 0.060342
Training Iteration 17: Minibatch Loss: 0.058865
Training Iteration 18: Minibatch Loss: 0.057579
Training Iteration 19: Minibatch Loss: 0.057363
Training Iteration 20: Minibatch Loss: 0.056306
Training Iteration 21: Minibatch Loss: 0.054852
Training Iteration 22: Minibatch Loss: 0.054921
Training Iteration 23: Minibatch Loss: 0.054607
Training Iteration 24: Minibatch Loss: 0.052088
Training Iteration 25: Minibatch Loss: 0.054686
Training Iteration 26: Minibatch Loss: 0.054302
Training Iteration 27: Minibatch Loss: 0.050364
Training Iteration 28: Minibatch Loss: 0.050816
Training Iteration 29: Minibatch Loss: 0.049654
Training Iteration 30: Minibatch Loss: 0.048772
Training Iteration 31: Minibatch Loss: 0.049306
Training Iteration 32: Minibatch Loss: 0.047199
Training Iteration 33: Minibatch Loss: 0.048526
Training Iteration 34: Minibatch Loss: 0.047316
Training Iteration 35: Minibatch Loss: 0.047077
Training Iteration 36: Minibatch Loss: 0.046487
Training Iteration 37: Minibatch Loss: 0.044247
Training Iteration 38: Minibatch Loss: 0.045869
Training Iteration 39: Minibatch Loss: 0.045192
Training Iteration 40: Minibatch Loss: 0.045501
Training Iteration 41: Minibatch Loss: 0.046352
Training Iteration 42: Minibatch Loss: 0.043994
Training Iteration 43: Minibatch Loss: 0.043591
Training Iteration 44: Minibatch Loss: 0.041642
Training Iteration 45: Minibatch Loss: 0.041552
Training Iteration 46: Minibatch Loss: 0.041293
Training Iteration 47: Minibatch Loss: 0.042692
Training Iteration 48: Minibatch Loss: 0.042602
Training Iteration 49: Minibatch Loss: 0.040573
Training Iteration 50: Minibatch Loss: 0.042619
Training Iteration 51: Minibatch Loss: 0.040020
Training Iteration 52: Minibatch Loss: 0.041451
Training Iteration 53: Minibatch Loss: 0.039619
Training Iteration 54: Minibatch Loss: 0.041061
Training Iteration 55: Minibatch Loss: 0.040360
Training Iteration 56: Minibatch Loss: 0.042640
Training Iteration 57: Minibatch Loss: 0.041365
Training Iteration 58: Minibatch Loss: 0.039746
Training Iteration 59: Minibatch Loss: 0.040101
Training Iteration 60: Minibatch Loss: 0.042556
Training Iteration 61: Minibatch Loss: 0.041223
Training Iteration 62: Minibatch Loss: 0.038255
Training Iteration 63: Minibatch Loss: 0.037757
Training Iteration 64: Minibatch Loss: 0.038347
Training Iteration 65: Minibatch Loss: 0.038267
Training Iteration 66: Minibatch Loss: 0.037663
Training Iteration 67: Minibatch Loss: 0.039590
Training Iteration 68: Minibatch Loss: 0.037736
Training Iteration 69: Minibatch Loss: 0.040558
Training Iteration 70: Minibatch Loss: 0.037408
Training Iteration 71: Minibatch Loss: 0.036609
Training Iteration 72: Minibatch Loss: 0.039049
Training Iteration 73: Minibatch Loss: 0.036910
Training Iteration 74: Minibatch Loss: 0.038262
Training Iteration 75: Minibatch Loss: 0.036760
Training Iteration 76: Minibatch Loss: 0.037274
Training Iteration 77: Minibatch Loss: 0.037120
Training Iteration 78: Minibatch Loss: 0.037497
Training Iteration 79: Minibatch Loss: 0.036565
Training Iteration 80: Minibatch Loss: 0.038191
Training Iteration 81: Minibatch Loss: 0.037631
Training Iteration 82: Minibatch Loss: 0.037232
Training Iteration 83: Minibatch Loss: 0.037471
Training Iteration 84: Minibatch Loss: 0.039072
Training Iteration 85: Minibatch Loss: 0.037279
Training Iteration 86: Minibatch Loss: 0.036950
Training Iteration 87: Minibatch Loss: 0.036745
Training Iteration 88: Minibatch Loss: 0.035789
Training Iteration 89: Minibatch Loss: 0.036584
Training Iteration 90: Minibatch Loss: 0.036243
Training Iteration 91: Minibatch Loss: 0.034293
Training Iteration 92: Minibatch Loss: 0.035367
Training Iteration 93: Minibatch Loss: 0.033825
Training Iteration 94: Minibatch Loss: 0.035387
Training Iteration 95: Minibatch Loss: 0.035348
Training Iteration 96: Minibatch Loss: 0.032727
Training Iteration 97: Minibatch Loss: 0.032390
Training Iteration 98: Minibatch Loss: 0.032703
Training Iteration 99: Minibatch Loss: 0.034751
Training Iteration 100: Minibatch Loss: 0.034554
Training Iteration 101: Minibatch Loss: 0.031467
Training Iteration 102: Minibatch Loss: 0.034373
Training Iteration 103: Minibatch Loss: 0.032436
Training Iteration 104: Minibatch Loss: 0.032457
Training Iteration 105: Minibatch Loss: 0.032604
Training Iteration 106: Minibatch Loss: 0.030848
Training Iteration 107: Minibatch Loss: 0.031473
Training Iteration 108: Minibatch Loss: 0.032038
Training Iteration 109: Minibatch Loss: 0.030331
Training Iteration 110: Minibatch Loss: 0.034081
Training Iteration 111: Minibatch Loss: 0.033003
Training Iteration 112: Minibatch Loss: 0.031662
Training Iteration 113: Minibatch Loss: 0.030772
Training Iteration 114: Minibatch Loss: 0.032354
Training Iteration 115: Minibatch Loss: 0.031417
Training Iteration 116: Minibatch Loss: 0.030157
Training Iteration 117: Minibatch Loss: 0.032286
Training Iteration 118: Minibatch Loss: 0.031888
Training Iteration 119: Minibatch Loss: 0.031065
Training Iteration 120: Minibatch Loss: 0.030830
Training Iteration 121: Minibatch Loss: 0.030522
Training Iteration 122: Minibatch Loss: 0.029497
Training Iteration 123: Minibatch Loss: 0.031301
Training Iteration 124: Minibatch Loss: 0.030660
Training Iteration 125: Minibatch Loss: 0.028019
Training Iteration 126: Minibatch Loss: 0.029857
Training Iteration 127: Minibatch Loss: 0.031159
Training Iteration 128: Minibatch Loss: 0.031554
Training Iteration 129: Minibatch Loss: 0.028769
Training Iteration 130: Minibatch Loss: 0.029693
Training Iteration 131: Minibatch Loss: 0.030606
Training Iteration 132: Minibatch Loss: 0.028727
Training Iteration 133: Minibatch Loss: 0.029593
Training Iteration 134: Minibatch Loss: 0.030346
Training Iteration 135: Minibatch Loss: 0.029944
Training Iteration 136: Minibatch Loss: 0.030351
Training Iteration 137: Minibatch Loss: 0.029385
Training Iteration 138: Minibatch Loss: 0.029697
Training Iteration 139: Minibatch Loss: 0.028607
Training Iteration 140: Minibatch Loss: 0.030069
Training Iteration 141: Minibatch Loss: 0.029058
Training Iteration 142: Minibatch Loss: 0.029414
Training Iteration 143: Minibatch Loss: 0.029178
Training Iteration 144: Minibatch Loss: 0.028738
Training Iteration 145: Minibatch Loss: 0.028102
Training Iteration 146: Minibatch Loss: 0.029465
Training Iteration 147: Minibatch Loss: 0.026696
Training Iteration 148: Minibatch Loss: 0.027477
Training Iteration 149: Minibatch Loss: 0.026748
Training Iteration 150: Minibatch Loss: 0.028520
Training Iteration 151: Minibatch Loss: 0.027223
Training Iteration 152: Minibatch Loss: 0.026102
Training Iteration 153: Minibatch Loss: 0.027453
Training Iteration 154: Minibatch Loss: 0.027186
Training Iteration 155: Minibatch Loss: 0.026194
Training Iteration 156: Minibatch Loss: 0.027579
Training Iteration 157: Minibatch Loss: 0.027260
Training Iteration 158: Minibatch Loss: 0.026346
Training Iteration 159: Minibatch Loss: 0.027160
Training Iteration 160: Minibatch Loss: 0.025642
Training Iteration 161: Minibatch Loss: 0.027758
Training Iteration 162: Minibatch Loss: 0.024648
Training Iteration 163: Minibatch Loss: 0.026365
Training Iteration 164: Minibatch Loss: 0.027692
Training Iteration 165: Minibatch Loss: 0.025067
Training Iteration 166: Minibatch Loss: 0.026471
Training Iteration 167: Minibatch Loss: 0.026017
Training Iteration 168: Minibatch Loss: 0.025265
Training Iteration 169: Minibatch Loss: 0.024560
Training Iteration 170: Minibatch Loss: 0.026187
Training Iteration 171: Minibatch Loss: 0.024745
Training Iteration 172: Minibatch Loss: 0.025247
Training Iteration 173: Minibatch Loss: 0.025566
Training Iteration 174: Minibatch Loss: 0.025665
Training Iteration 175: Minibatch Loss: 0.026676
Training Iteration 176: Minibatch Loss: 0.026918
Training Iteration 177: Minibatch Loss: 0.024832
Training Iteration 178: Minibatch Loss: 0.026332
Training Iteration 179: Minibatch Loss: 0.026600
Training Iteration 180: Minibatch Loss: 0.024423
Training Iteration 181: Minibatch Loss: 0.023768
Training Iteration 182: Minibatch Loss: 0.023935
Training Iteration 183: Minibatch Loss: 0.024937
Training Iteration 184: Minibatch Loss: 0.023065
Training Iteration 185: Minibatch Loss: 0.025644
Training Iteration 186: Minibatch Loss: 0.024610
Training Iteration 187: Minibatch Loss: 0.025125
Training Iteration 188: Minibatch Loss: 0.023132
Training Iteration 189: Minibatch Loss: 0.024969
Training Iteration 190: Minibatch Loss: 0.024050
Training Iteration 191: Minibatch Loss: 0.023051
Training Iteration 192: Minibatch Loss: 0.024250
Training Iteration 193: Minibatch Loss: 0.024691
Training Iteration 194: Minibatch Loss: 0.024628
Training Iteration 195: Minibatch Loss: 0.025658
Training Iteration 196: Minibatch Loss: 0.023735
Training Iteration 197: Minibatch Loss: 0.023197
Training Iteration 198: Minibatch Loss: 0.024095
Training Iteration 199: Minibatch Loss: 0.024547
Training Iteration 200: Minibatch Loss: 0.023658
Training Iteration 201: Minibatch Loss: 0.025042
Training Iteration 202: Minibatch Loss: 0.023404
Training Iteration 203: Minibatch Loss: 0.025156
Training Iteration 204: Minibatch Loss: 0.024040
Training Iteration 205: Minibatch Loss: 0.024787
Training Iteration 206: Minibatch Loss: 0.023945
Training Iteration 207: Minibatch Loss: 0.024650
Training Iteration 208: Minibatch Loss: 0.024854
Training Iteration 209: Minibatch Loss: 0.022778
Training Iteration 210: Minibatch Loss: 0.024505
Training Iteration 211: Minibatch Loss: 0.023429
Training Iteration 212: Minibatch Loss: 0.023127
Training Iteration 213: Minibatch Loss: 0.026023
Training Iteration 214: Minibatch Loss: 0.023046
Training Iteration 215: Minibatch Loss: 0.023228
Training Iteration 216: Minibatch Loss: 0.022154
Training Iteration 217: Minibatch Loss: 0.024282
Training Iteration 218: Minibatch Loss: 0.023658
Training Iteration 219: Minibatch Loss: 0.022470
Training Iteration 220: Minibatch Loss: 0.023310
Training Iteration 221: Minibatch Loss: 0.024507
Training Iteration 222: Minibatch Loss: 0.023011
Training Iteration 223: Minibatch Loss: 0.024128
Training Iteration 224: Minibatch Loss: 0.024275
Training Iteration 225: Minibatch Loss: 0.023020
Training Iteration 226: Minibatch Loss: 0.024138
Training Iteration 227: Minibatch Loss: 0.021647
Training Iteration 228: Minibatch Loss: 0.022558
Training Iteration 229: Minibatch Loss: 0.023156
Training Iteration 230: Minibatch Loss: 0.022324
Training Iteration 231: Minibatch Loss: 0.021441
Training Iteration 232: Minibatch Loss: 0.022479
Training Iteration 233: Minibatch Loss: 0.022161
Training Iteration 234: Minibatch Loss: 0.020478
Training Iteration 235: Minibatch Loss: 0.023210
Training Iteration 236: Minibatch Loss: 0.022333
Training Iteration 237: Minibatch Loss: 0.022221
Training Iteration 238: Minibatch Loss: 0.021408
Training Iteration 239: Minibatch Loss: 0.021936
Training Iteration 240: Minibatch Loss: 0.021471
Training Iteration 241: Minibatch Loss: 0.020488
Training Iteration 242: Minibatch Loss: 0.022066
Training Iteration 243: Minibatch Loss: 0.020656
Training Iteration 244: Minibatch Loss: 0.020676
Training Iteration 245: Minibatch Loss: 0.022629
Training Iteration 246: Minibatch Loss: 0.022749
Training Iteration 247: Minibatch Loss: 0.021789
Training Iteration 248: Minibatch Loss: 0.021685
Training Iteration 249: Minibatch Loss: 0.022546
Training Iteration 250: Minibatch Loss: 0.021055
Training Iteration 251: Minibatch Loss: 0.021676
Training Iteration 252: Minibatch Loss: 0.023775
Training Iteration 253: Minibatch Loss: 0.020360
Training Iteration 254: Minibatch Loss: 0.022561
Training Iteration 255: Minibatch Loss: 0.021193
Training Iteration 256: Minibatch Loss: 0.021448
Training Iteration 257: Minibatch Loss: 0.020959
Training Iteration 258: Minibatch Loss: 0.021550
Training Iteration 259: Minibatch Loss: 0.021298
Training Iteration 260: Minibatch Loss: 0.022643
Training Iteration 261: Minibatch Loss: 0.021914
Training Iteration 262: Minibatch Loss: 0.021178
Training Iteration 263: Minibatch Loss: 0.020708
Training Iteration 264: Minibatch Loss: 0.022216
Training Iteration 265: Minibatch Loss: 0.021725
Training Iteration 266: Minibatch Loss: 0.024039
Training Iteration 267: Minibatch Loss: 0.022130
Training Iteration 268: Minibatch Loss: 0.021418
Training Iteration 269: Minibatch Loss: 0.020530
Training Iteration 270: Minibatch Loss: 0.022362
Training Iteration 271: Minibatch Loss: 0.020455
Training Iteration 272: Minibatch Loss: 0.021698
Training Iteration 273: Minibatch Loss: 0.020186
Training Iteration 274: Minibatch Loss: 0.019669
Training Iteration 275: Minibatch Loss: 0.018919
Training Iteration 276: Minibatch Loss: 0.019789
Training Iteration 277: Minibatch Loss: 0.019870
Training Iteration 278: Minibatch Loss: 0.020134
Training Iteration 279: Minibatch Loss: 0.019467
Training Iteration 280: Minibatch Loss: 0.021306
Training Iteration 281: Minibatch Loss: 0.019435
Training Iteration 282: Minibatch Loss: 0.019673
Training Iteration 283: Minibatch Loss: 0.019764
Training Iteration 284: Minibatch Loss: 0.019866
Training Iteration 285: Minibatch Loss: 0.019296
Training Iteration 286: Minibatch Loss: 0.020957
Training Iteration 287: Minibatch Loss: 0.020330
Training Iteration 288: Minibatch Loss: 0.019456
Training Iteration 289: Minibatch Loss: 0.019935
Training Iteration 290: Minibatch Loss: 0.019617
Training Iteration 291: Minibatch Loss: 0.019591
Training Iteration 292: Minibatch Loss: 0.018114
Training Iteration 293: Minibatch Loss: 0.017542
Training Iteration 294: Minibatch Loss: 0.017341
Training Iteration 295: Minibatch Loss: 0.017382
Training Iteration 296: Minibatch Loss: 0.018450
Training Iteration 297: Minibatch Loss: 0.017796
Training Iteration 298: Minibatch Loss: 0.017507
Training Iteration 299: Minibatch Loss: 0.017531
Training Iteration 300: Minibatch Loss: 0.017383
Training Iteration 301: Minibatch Loss: 0.019170
Training Iteration 302: Minibatch Loss: 0.019854
Training Iteration 303: Minibatch Loss: 0.018949
Training Iteration 304: Minibatch Loss: 0.017977
Training Iteration 305: Minibatch Loss: 0.016964
Training Iteration 306: Minibatch Loss: 0.019310
Training Iteration 307: Minibatch Loss: 0.017257
Training Iteration 308: Minibatch Loss: 0.017363
Training Iteration 309: Minibatch Loss: 0.017201
Training Iteration 310: Minibatch Loss: 0.018682
Training Iteration 311: Minibatch Loss: 0.017068
Training Iteration 312: Minibatch Loss: 0.018366
Training Iteration 313: Minibatch Loss: 0.017626
Training Iteration 314: Minibatch Loss: 0.018603
Training Iteration 315: Minibatch Loss: 0.018568
Training Iteration 316: Minibatch Loss: 0.017143
Training Iteration 317: Minibatch Loss: 0.017055
Training Iteration 318: Minibatch Loss: 0.018225
Training Iteration 319: Minibatch Loss: 0.017484
Training Iteration 320: Minibatch Loss: 0.018590
Training Iteration 321: Minibatch Loss: 0.018235
Training Iteration 322: Minibatch Loss: 0.016714
Training Iteration 323: Minibatch Loss: 0.016598
Training Iteration 324: Minibatch Loss: 0.017755
Training Iteration 325: Minibatch Loss: 0.016961
Training Iteration 326: Minibatch Loss: 0.016860
Training Iteration 327: Minibatch Loss: 0.016733
Training Iteration 328: Minibatch Loss: 0.017502
Training Iteration 329: Minibatch Loss: 0.017433
Training Iteration 330: Minibatch Loss: 0.017259
Training Iteration 331: Minibatch Loss: 0.018246
Training Iteration 332: Minibatch Loss: 0.017005
Training Iteration 333: Minibatch Loss: 0.016125
Training Iteration 334: Minibatch Loss: 0.016933
Training Iteration 335: Minibatch Loss: 0.017229
Training Iteration 336: Minibatch Loss: 0.016016
Training Iteration 337: Minibatch Loss: 0.016272
Training Iteration 338: Minibatch Loss: 0.017799
Training Iteration 339: Minibatch Loss: 0.017201
Training Iteration 340: Minibatch Loss: 0.016652
Training Iteration 341: Minibatch Loss: 0.016737
Training Iteration 342: Minibatch Loss: 0.016818
Training Iteration 343: Minibatch Loss: 0.017661
Training Iteration 344: Minibatch Loss: 0.016562
Training Iteration 345: Minibatch Loss: 0.016745
Training Iteration 346: Minibatch Loss: 0.018050
Training Iteration 347: Minibatch Loss: 0.016034
Training Iteration 348: Minibatch Loss: 0.016493
Training Iteration 349: Minibatch Loss: 0.017358
Training Iteration 350: Minibatch Loss: 0.016688
Training Iteration 351: Minibatch Loss: 0.016980
Training Iteration 352: Minibatch Loss: 0.017442
Training Iteration 353: Minibatch Loss: 0.016899
Training Iteration 354: Minibatch Loss: 0.016437
Training Iteration 355: Minibatch Loss: 0.018226
Training Iteration 356: Minibatch Loss: 0.016750
Training Iteration 357: Minibatch Loss: 0.017375
Training Iteration 358: Minibatch Loss: 0.016383
Training Iteration 359: Minibatch Loss: 0.016797
Training Iteration 360: Minibatch Loss: 0.016423
Training Iteration 361: Minibatch Loss: 0.017455
Training Iteration 362: Minibatch Loss: 0.017247
Training Iteration 363: Minibatch Loss: 0.018659
Training Iteration 364: Minibatch Loss: 0.016957
Training Iteration 365: Minibatch Loss: 0.016854
Training Iteration 366: Minibatch Loss: 0.016534
Training Iteration 367: Minibatch Loss: 0.016165
Training Iteration 368: Minibatch Loss: 0.015912
Training Iteration 369: Minibatch Loss: 0.016029
Training Iteration 370: Minibatch Loss: 0.017305
Training Iteration 371: Minibatch Loss: 0.016429
Training Iteration 372: Minibatch Loss: 0.016978
Training Iteration 373: Minibatch Loss: 0.015694
Training Iteration 374: Minibatch Loss: 0.016695
Training Iteration 375: Minibatch Loss: 0.016507
Training Iteration 376: Minibatch Loss: 0.016246
Training Iteration 377: Minibatch Loss: 0.016837
Training Iteration 378: Minibatch Loss: 0.017078
Training Iteration 379: Minibatch Loss: 0.015459
Training Iteration 380: Minibatch Loss: 0.016605
Training Iteration 381: Minibatch Loss: 0.018035
Training Iteration 382: Minibatch Loss: 0.016724
Training Iteration 383: Minibatch Loss: 0.016653
Training Iteration 384: Minibatch Loss: 0.015461
Training Iteration 385: Minibatch Loss: 0.017056
Training Iteration 386: Minibatch Loss: 0.017926
Training Iteration 387: Minibatch Loss: 0.016534
Training Iteration 388: Minibatch Loss: 0.015076
Training Iteration 389: Minibatch Loss: 0.016646
Training Iteration 390: Minibatch Loss: 0.015846
Training Iteration 391: Minibatch Loss: 0.018024
Training Iteration 392: Minibatch Loss: 0.017301
Training Iteration 393: Minibatch Loss: 0.016513
Training Iteration 394: Minibatch Loss: 0.016369
Training Iteration 395: Minibatch Loss: 0.016168
Training Iteration 396: Minibatch Loss: 0.016526
Training Iteration 397: Minibatch Loss: 0.016961
Training Iteration 398: Minibatch Loss: 0.015807
Training Iteration 399: Minibatch Loss: 0.016079
Training Iteration 400: Minibatch Loss: 0.016699
Training Iteration 401: Minibatch Loss: 0.016393
Training Iteration 402: Minibatch Loss: 0.015562
Training Iteration 403: Minibatch Loss: 0.016515
Training Iteration 404: Minibatch Loss: 0.017716
Training Iteration 405: Minibatch Loss: 0.016726
Training Iteration 406: Minibatch Loss: 0.015985
Training Iteration 407: Minibatch Loss: 0.016794
Training Iteration 408: Minibatch Loss: 0.017726
Training Iteration 409: Minibatch Loss: 0.017069
Training Iteration 410: Minibatch Loss: 0.016315
Training Iteration 411: Minibatch Loss: 0.015190
Training Iteration 412: Minibatch Loss: 0.016252
Training Iteration 413: Minibatch Loss: 0.017470
Training Iteration 414: Minibatch Loss: 0.016143
Training Iteration 415: Minibatch Loss: 0.016161
Training Iteration 416: Minibatch Loss: 0.015918
Training Iteration 417: Minibatch Loss: 0.015382
Training Iteration 418: Minibatch Loss: 0.016566
Training Iteration 419: Minibatch Loss: 0.016004
Training Iteration 420: Minibatch Loss: 0.017348
Training Iteration 421: Minibatch Loss: 0.017079
Training Iteration 422: Minibatch Loss: 0.016944
Training Iteration 423: Minibatch Loss: 0.015007
Training Iteration 424: Minibatch Loss: 0.015777
Training Iteration 425: Minibatch Loss: 0.016258
Training Iteration 426: Minibatch Loss: 0.016691
Training Iteration 427: Minibatch Loss: 0.016351
Training Iteration 428: Minibatch Loss: 0.015015
Training Iteration 429: Minibatch Loss: 0.014038
Training Iteration 430: Minibatch Loss: 0.014863
Training Iteration 431: Minibatch Loss: 0.014495
Training Iteration 432: Minibatch Loss: 0.013285
Training Iteration 433: Minibatch Loss: 0.013820
Training Iteration 434: Minibatch Loss: 0.015043
Training Iteration 435: Minibatch Loss: 0.014432
Training Iteration 436: Minibatch Loss: 0.015722
Training Iteration 437: Minibatch Loss: 0.014461
Training Iteration 438: Minibatch Loss: 0.015097
Training Iteration 439: Minibatch Loss: 0.014191
Training Iteration 440: Minibatch Loss: 0.014372
Training Iteration 441: Minibatch Loss: 0.015438
Training Iteration 442: Minibatch Loss: 0.014882
Training Iteration 443: Minibatch Loss: 0.015094
Training Iteration 444: Minibatch Loss: 0.014242
Training Iteration 445: Minibatch Loss: 0.014769
Training Iteration 446: Minibatch Loss: 0.014840
Training Iteration 447: Minibatch Loss: 0.014436
Training Iteration 448: Minibatch Loss: 0.015723
Training Iteration 449: Minibatch Loss: 0.015246
Test Loss: 0.014669
