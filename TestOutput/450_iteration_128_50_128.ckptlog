Training Iteration 1: Minibatch Loss: 0.163704
Training Iteration 2: Minibatch Loss: 0.109875
Training Iteration 3: Minibatch Loss: 0.090449
Training Iteration 4: Minibatch Loss: 0.087360
Training Iteration 5: Minibatch Loss: 0.083302
Training Iteration 6: Minibatch Loss: 0.079673
Training Iteration 7: Minibatch Loss: 0.073889
Training Iteration 8: Minibatch Loss: 0.071541
Training Iteration 9: Minibatch Loss: 0.067981
Training Iteration 10: Minibatch Loss: 0.065598
Training Iteration 11: Minibatch Loss: 0.064764
Training Iteration 12: Minibatch Loss: 0.061864
Training Iteration 13: Minibatch Loss: 0.061388
Training Iteration 14: Minibatch Loss: 0.057757
Training Iteration 15: Minibatch Loss: 0.057549
Training Iteration 16: Minibatch Loss: 0.056134
Training Iteration 17: Minibatch Loss: 0.052646
Training Iteration 18: Minibatch Loss: 0.055353
Training Iteration 19: Minibatch Loss: 0.053831
Training Iteration 20: Minibatch Loss: 0.053001
Training Iteration 21: Minibatch Loss: 0.051833
Training Iteration 22: Minibatch Loss: 0.052800
Training Iteration 23: Minibatch Loss: 0.050759
Training Iteration 24: Minibatch Loss: 0.047640
Training Iteration 25: Minibatch Loss: 0.048397
Training Iteration 26: Minibatch Loss: 0.047430
Training Iteration 27: Minibatch Loss: 0.045622
Training Iteration 28: Minibatch Loss: 0.047786
Training Iteration 29: Minibatch Loss: 0.045909
Training Iteration 30: Minibatch Loss: 0.045832
Training Iteration 31: Minibatch Loss: 0.047301
Training Iteration 32: Minibatch Loss: 0.042779
Training Iteration 33: Minibatch Loss: 0.041956
Training Iteration 34: Minibatch Loss: 0.042764
Training Iteration 35: Minibatch Loss: 0.044002
Training Iteration 36: Minibatch Loss: 0.039718
Training Iteration 37: Minibatch Loss: 0.040391
Training Iteration 38: Minibatch Loss: 0.039816
Training Iteration 39: Minibatch Loss: 0.041540
Training Iteration 40: Minibatch Loss: 0.042661
Training Iteration 41: Minibatch Loss: 0.040540
Training Iteration 42: Minibatch Loss: 0.039990
Training Iteration 43: Minibatch Loss: 0.039801
Training Iteration 44: Minibatch Loss: 0.039517
Training Iteration 45: Minibatch Loss: 0.040353
Training Iteration 46: Minibatch Loss: 0.040404
Training Iteration 47: Minibatch Loss: 0.039533
Training Iteration 48: Minibatch Loss: 0.036163
Training Iteration 49: Minibatch Loss: 0.038983
Training Iteration 50: Minibatch Loss: 0.037257
Training Iteration 51: Minibatch Loss: 0.034739
Training Iteration 52: Minibatch Loss: 0.036207
Training Iteration 53: Minibatch Loss: 0.037534
Training Iteration 54: Minibatch Loss: 0.035074
Training Iteration 55: Minibatch Loss: 0.034990
Training Iteration 56: Minibatch Loss: 0.034891
Training Iteration 57: Minibatch Loss: 0.034540
Training Iteration 58: Minibatch Loss: 0.033605
Training Iteration 59: Minibatch Loss: 0.032839
Training Iteration 60: Minibatch Loss: 0.033476
Training Iteration 61: Minibatch Loss: 0.035244
Training Iteration 62: Minibatch Loss: 0.032804
Training Iteration 63: Minibatch Loss: 0.032954
Training Iteration 64: Minibatch Loss: 0.031541
Training Iteration 65: Minibatch Loss: 0.033833
Training Iteration 66: Minibatch Loss: 0.031913
Training Iteration 67: Minibatch Loss: 0.031348
Training Iteration 68: Minibatch Loss: 0.032676
Training Iteration 69: Minibatch Loss: 0.032055
Training Iteration 70: Minibatch Loss: 0.031839
Training Iteration 71: Minibatch Loss: 0.032930
Training Iteration 72: Minibatch Loss: 0.032200
Training Iteration 73: Minibatch Loss: 0.031439
Training Iteration 74: Minibatch Loss: 0.030900
Training Iteration 75: Minibatch Loss: 0.029445
Training Iteration 76: Minibatch Loss: 0.031225
Training Iteration 77: Minibatch Loss: 0.030706
Training Iteration 78: Minibatch Loss: 0.030730
Training Iteration 79: Minibatch Loss: 0.030037
Training Iteration 80: Minibatch Loss: 0.028552
Training Iteration 81: Minibatch Loss: 0.026823
Training Iteration 82: Minibatch Loss: 0.027273
Training Iteration 83: Minibatch Loss: 0.028799
Training Iteration 84: Minibatch Loss: 0.027880
Training Iteration 85: Minibatch Loss: 0.027004
Training Iteration 86: Minibatch Loss: 0.028890
Training Iteration 87: Minibatch Loss: 0.027157
Training Iteration 88: Minibatch Loss: 0.026930
Training Iteration 89: Minibatch Loss: 0.027677
Training Iteration 90: Minibatch Loss: 0.026243
Training Iteration 91: Minibatch Loss: 0.025130
Training Iteration 92: Minibatch Loss: 0.026087
Training Iteration 93: Minibatch Loss: 0.025452
Training Iteration 94: Minibatch Loss: 0.025200
Training Iteration 95: Minibatch Loss: 0.023778
Training Iteration 96: Minibatch Loss: 0.025214
Training Iteration 97: Minibatch Loss: 0.024341
Training Iteration 98: Minibatch Loss: 0.025973
Training Iteration 99: Minibatch Loss: 0.024838
Training Iteration 100: Minibatch Loss: 0.023990
Training Iteration 101: Minibatch Loss: 0.023777
Training Iteration 102: Minibatch Loss: 0.023891
Training Iteration 103: Minibatch Loss: 0.024562
Training Iteration 104: Minibatch Loss: 0.025306
Training Iteration 105: Minibatch Loss: 0.026196
Training Iteration 106: Minibatch Loss: 0.024795
Training Iteration 107: Minibatch Loss: 0.025466
Training Iteration 108: Minibatch Loss: 0.023656
Training Iteration 109: Minibatch Loss: 0.024203
Training Iteration 110: Minibatch Loss: 0.024983
Training Iteration 111: Minibatch Loss: 0.022579
Training Iteration 112: Minibatch Loss: 0.023915
Training Iteration 113: Minibatch Loss: 0.024384
Training Iteration 114: Minibatch Loss: 0.024245
Training Iteration 115: Minibatch Loss: 0.022366
Training Iteration 116: Minibatch Loss: 0.023890
Training Iteration 117: Minibatch Loss: 0.024534
Training Iteration 118: Minibatch Loss: 0.023128
Training Iteration 119: Minibatch Loss: 0.023824
Training Iteration 120: Minibatch Loss: 0.022344
Training Iteration 121: Minibatch Loss: 0.022672
Training Iteration 122: Minibatch Loss: 0.023663
Training Iteration 123: Minibatch Loss: 0.024269
Training Iteration 124: Minibatch Loss: 0.023869
Training Iteration 125: Minibatch Loss: 0.022270
Training Iteration 126: Minibatch Loss: 0.023195
Training Iteration 127: Minibatch Loss: 0.022682
Training Iteration 128: Minibatch Loss: 0.022403
Training Iteration 129: Minibatch Loss: 0.024339
Training Iteration 130: Minibatch Loss: 0.022696
Training Iteration 131: Minibatch Loss: 0.023712
Training Iteration 132: Minibatch Loss: 0.022219
Training Iteration 133: Minibatch Loss: 0.021846
Training Iteration 134: Minibatch Loss: 0.021964
Training Iteration 135: Minibatch Loss: 0.023707
Training Iteration 136: Minibatch Loss: 0.021797
Training Iteration 137: Minibatch Loss: 0.022146
Training Iteration 138: Minibatch Loss: 0.021916
Training Iteration 139: Minibatch Loss: 0.020933
Training Iteration 140: Minibatch Loss: 0.022320
Training Iteration 141: Minibatch Loss: 0.021213
Training Iteration 142: Minibatch Loss: 0.021076
Training Iteration 143: Minibatch Loss: 0.020310
Training Iteration 144: Minibatch Loss: 0.020919
Training Iteration 145: Minibatch Loss: 0.019877
Training Iteration 146: Minibatch Loss: 0.020199
Training Iteration 147: Minibatch Loss: 0.021191
Training Iteration 148: Minibatch Loss: 0.021480
Training Iteration 149: Minibatch Loss: 0.021246
Training Iteration 150: Minibatch Loss: 0.020697
Training Iteration 151: Minibatch Loss: 0.020561
Training Iteration 152: Minibatch Loss: 0.021496
Training Iteration 153: Minibatch Loss: 0.019232
Training Iteration 154: Minibatch Loss: 0.020673
Training Iteration 155: Minibatch Loss: 0.020755
Training Iteration 156: Minibatch Loss: 0.020374
Training Iteration 157: Minibatch Loss: 0.020002
Training Iteration 158: Minibatch Loss: 0.021881
Training Iteration 159: Minibatch Loss: 0.021713
Training Iteration 160: Minibatch Loss: 0.021985
Training Iteration 161: Minibatch Loss: 0.020727
Training Iteration 162: Minibatch Loss: 0.020283
Training Iteration 163: Minibatch Loss: 0.020318
Training Iteration 164: Minibatch Loss: 0.020041
Training Iteration 165: Minibatch Loss: 0.019464
Training Iteration 166: Minibatch Loss: 0.020170
Training Iteration 167: Minibatch Loss: 0.019370
Training Iteration 168: Minibatch Loss: 0.019134
Training Iteration 169: Minibatch Loss: 0.019719
Training Iteration 170: Minibatch Loss: 0.019106
Training Iteration 171: Minibatch Loss: 0.021222
Training Iteration 172: Minibatch Loss: 0.019897
Training Iteration 173: Minibatch Loss: 0.021025
Training Iteration 174: Minibatch Loss: 0.020135
Training Iteration 175: Minibatch Loss: 0.021347
Training Iteration 176: Minibatch Loss: 0.021713
Training Iteration 177: Minibatch Loss: 0.019872
Training Iteration 178: Minibatch Loss: 0.020198
Training Iteration 179: Minibatch Loss: 0.019091
Training Iteration 180: Minibatch Loss: 0.018640
Training Iteration 181: Minibatch Loss: 0.019006
Training Iteration 182: Minibatch Loss: 0.017099
Training Iteration 183: Minibatch Loss: 0.017961
Training Iteration 184: Minibatch Loss: 0.017978
Training Iteration 185: Minibatch Loss: 0.017172
Training Iteration 186: Minibatch Loss: 0.018483
Training Iteration 187: Minibatch Loss: 0.018874
Training Iteration 188: Minibatch Loss: 0.017678
Training Iteration 189: Minibatch Loss: 0.020604
Training Iteration 190: Minibatch Loss: 0.018018
Training Iteration 191: Minibatch Loss: 0.017753
Training Iteration 192: Minibatch Loss: 0.019041
Training Iteration 193: Minibatch Loss: 0.017852
Training Iteration 194: Minibatch Loss: 0.017386
Training Iteration 195: Minibatch Loss: 0.018044
Training Iteration 196: Minibatch Loss: 0.017912
Training Iteration 197: Minibatch Loss: 0.016809
Training Iteration 198: Minibatch Loss: 0.017909
Training Iteration 199: Minibatch Loss: 0.018517
Training Iteration 200: Minibatch Loss: 0.017041
Training Iteration 201: Minibatch Loss: 0.017088
Training Iteration 202: Minibatch Loss: 0.016153
Training Iteration 203: Minibatch Loss: 0.017706
Training Iteration 204: Minibatch Loss: 0.016616
Training Iteration 205: Minibatch Loss: 0.016653
Training Iteration 206: Minibatch Loss: 0.019023
Training Iteration 207: Minibatch Loss: 0.016792
Training Iteration 208: Minibatch Loss: 0.018046
Training Iteration 209: Minibatch Loss: 0.017778
Training Iteration 210: Minibatch Loss: 0.019552
Training Iteration 211: Minibatch Loss: 0.016927
Training Iteration 212: Minibatch Loss: 0.016854
Training Iteration 213: Minibatch Loss: 0.018220
Training Iteration 214: Minibatch Loss: 0.017645
Training Iteration 215: Minibatch Loss: 0.016495
Training Iteration 216: Minibatch Loss: 0.017397
Training Iteration 217: Minibatch Loss: 0.016116
Training Iteration 218: Minibatch Loss: 0.017806
Training Iteration 219: Minibatch Loss: 0.016771
Training Iteration 220: Minibatch Loss: 0.017228
Training Iteration 221: Minibatch Loss: 0.016298
Training Iteration 222: Minibatch Loss: 0.018148
Training Iteration 223: Minibatch Loss: 0.017293
Training Iteration 224: Minibatch Loss: 0.016121
Training Iteration 225: Minibatch Loss: 0.019294
Training Iteration 226: Minibatch Loss: 0.016288
Training Iteration 227: Minibatch Loss: 0.016854
Training Iteration 228: Minibatch Loss: 0.017592
Training Iteration 229: Minibatch Loss: 0.015202
Training Iteration 230: Minibatch Loss: 0.016323
Training Iteration 231: Minibatch Loss: 0.015895
Training Iteration 232: Minibatch Loss: 0.017037
Training Iteration 233: Minibatch Loss: 0.015748
Training Iteration 234: Minibatch Loss: 0.016710
Training Iteration 235: Minibatch Loss: 0.016960
Training Iteration 236: Minibatch Loss: 0.016335
Training Iteration 237: Minibatch Loss: 0.015728
Training Iteration 238: Minibatch Loss: 0.015804
Training Iteration 239: Minibatch Loss: 0.015427
Training Iteration 240: Minibatch Loss: 0.015743
Training Iteration 241: Minibatch Loss: 0.014745
Training Iteration 242: Minibatch Loss: 0.016159
Training Iteration 243: Minibatch Loss: 0.015333
Training Iteration 244: Minibatch Loss: 0.015633
Training Iteration 245: Minibatch Loss: 0.015006
Training Iteration 246: Minibatch Loss: 0.015823
Training Iteration 247: Minibatch Loss: 0.016502
Training Iteration 248: Minibatch Loss: 0.016307
Training Iteration 249: Minibatch Loss: 0.016930
Training Iteration 250: Minibatch Loss: 0.015473
Training Iteration 251: Minibatch Loss: 0.016441
Training Iteration 252: Minibatch Loss: 0.015521
Training Iteration 253: Minibatch Loss: 0.015999
Training Iteration 254: Minibatch Loss: 0.015753
Training Iteration 255: Minibatch Loss: 0.015455
Training Iteration 256: Minibatch Loss: 0.015113
Training Iteration 257: Minibatch Loss: 0.015103
Training Iteration 258: Minibatch Loss: 0.015343
Training Iteration 259: Minibatch Loss: 0.016553
Training Iteration 260: Minibatch Loss: 0.015202
Training Iteration 261: Minibatch Loss: 0.017371
Training Iteration 262: Minibatch Loss: 0.015369
Training Iteration 263: Minibatch Loss: 0.014591
Training Iteration 264: Minibatch Loss: 0.015696
Training Iteration 265: Minibatch Loss: 0.015128
Training Iteration 266: Minibatch Loss: 0.014040
Training Iteration 267: Minibatch Loss: 0.015171
Training Iteration 268: Minibatch Loss: 0.015321
Training Iteration 269: Minibatch Loss: 0.014336
Training Iteration 270: Minibatch Loss: 0.015190
Training Iteration 271: Minibatch Loss: 0.015106
Training Iteration 272: Minibatch Loss: 0.014031
Training Iteration 273: Minibatch Loss: 0.014881
Training Iteration 274: Minibatch Loss: 0.016291
Training Iteration 275: Minibatch Loss: 0.015512
Training Iteration 276: Minibatch Loss: 0.015879
Training Iteration 277: Minibatch Loss: 0.013751
Training Iteration 278: Minibatch Loss: 0.014794
Training Iteration 279: Minibatch Loss: 0.016431
Training Iteration 280: Minibatch Loss: 0.015731
Training Iteration 281: Minibatch Loss: 0.014834
Training Iteration 282: Minibatch Loss: 0.014684
Training Iteration 283: Minibatch Loss: 0.013893
Training Iteration 284: Minibatch Loss: 0.015397
Training Iteration 285: Minibatch Loss: 0.014484
Training Iteration 286: Minibatch Loss: 0.014153
Training Iteration 287: Minibatch Loss: 0.014545
Training Iteration 288: Minibatch Loss: 0.016387
Training Iteration 289: Minibatch Loss: 0.015615
Training Iteration 290: Minibatch Loss: 0.014200
Training Iteration 291: Minibatch Loss: 0.013599
Training Iteration 292: Minibatch Loss: 0.015128
Training Iteration 293: Minibatch Loss: 0.014679
Training Iteration 294: Minibatch Loss: 0.015904
Training Iteration 295: Minibatch Loss: 0.014599
Training Iteration 296: Minibatch Loss: 0.014375
Training Iteration 297: Minibatch Loss: 0.014800
Training Iteration 298: Minibatch Loss: 0.014398
Training Iteration 299: Minibatch Loss: 0.014233
Training Iteration 300: Minibatch Loss: 0.015411
Training Iteration 301: Minibatch Loss: 0.016505
Training Iteration 302: Minibatch Loss: 0.014220
Training Iteration 303: Minibatch Loss: 0.014608
Training Iteration 304: Minibatch Loss: 0.014832
Training Iteration 305: Minibatch Loss: 0.013907
Training Iteration 306: Minibatch Loss: 0.013711
Training Iteration 307: Minibatch Loss: 0.015348
Training Iteration 308: Minibatch Loss: 0.014377
Training Iteration 309: Minibatch Loss: 0.014509
Training Iteration 310: Minibatch Loss: 0.014403
Training Iteration 311: Minibatch Loss: 0.014828
Training Iteration 312: Minibatch Loss: 0.013732
Training Iteration 313: Minibatch Loss: 0.015361
Training Iteration 314: Minibatch Loss: 0.013439
Training Iteration 315: Minibatch Loss: 0.013944
Training Iteration 316: Minibatch Loss: 0.014037
Training Iteration 317: Minibatch Loss: 0.013208
Training Iteration 318: Minibatch Loss: 0.014703
Training Iteration 319: Minibatch Loss: 0.014491
Training Iteration 320: Minibatch Loss: 0.015126
Training Iteration 321: Minibatch Loss: 0.014618
Training Iteration 322: Minibatch Loss: 0.014227
Training Iteration 323: Minibatch Loss: 0.014383
Training Iteration 324: Minibatch Loss: 0.014663
Training Iteration 325: Minibatch Loss: 0.014990
Training Iteration 326: Minibatch Loss: 0.013410
Training Iteration 327: Minibatch Loss: 0.014245
Training Iteration 328: Minibatch Loss: 0.013804
Training Iteration 329: Minibatch Loss: 0.015272
Training Iteration 330: Minibatch Loss: 0.014661
Training Iteration 331: Minibatch Loss: 0.014850
Training Iteration 332: Minibatch Loss: 0.013376
Training Iteration 333: Minibatch Loss: 0.014534
Training Iteration 334: Minibatch Loss: 0.014008
Training Iteration 335: Minibatch Loss: 0.014598
Training Iteration 336: Minibatch Loss: 0.014829
Training Iteration 337: Minibatch Loss: 0.014161
Training Iteration 338: Minibatch Loss: 0.014843
Training Iteration 339: Minibatch Loss: 0.013502
Training Iteration 340: Minibatch Loss: 0.014939
Training Iteration 341: Minibatch Loss: 0.013868
Training Iteration 342: Minibatch Loss: 0.013536
Training Iteration 343: Minibatch Loss: 0.014749
Training Iteration 344: Minibatch Loss: 0.014415
Training Iteration 345: Minibatch Loss: 0.015409
Training Iteration 346: Minibatch Loss: 0.014960
Training Iteration 347: Minibatch Loss: 0.014068
Training Iteration 348: Minibatch Loss: 0.013456
Training Iteration 349: Minibatch Loss: 0.014537
Training Iteration 350: Minibatch Loss: 0.014155
Training Iteration 351: Minibatch Loss: 0.014206
Training Iteration 352: Minibatch Loss: 0.013435
Training Iteration 353: Minibatch Loss: 0.013902
Training Iteration 354: Minibatch Loss: 0.014963
Training Iteration 355: Minibatch Loss: 0.013945
Training Iteration 356: Minibatch Loss: 0.013785
Training Iteration 357: Minibatch Loss: 0.013865
Training Iteration 358: Minibatch Loss: 0.014800
Training Iteration 359: Minibatch Loss: 0.013373
Training Iteration 360: Minibatch Loss: 0.014917
Training Iteration 361: Minibatch Loss: 0.014202
Training Iteration 362: Minibatch Loss: 0.013378
Training Iteration 363: Minibatch Loss: 0.013898
Training Iteration 364: Minibatch Loss: 0.014428
Training Iteration 365: Minibatch Loss: 0.014043
Training Iteration 366: Minibatch Loss: 0.013387
Training Iteration 367: Minibatch Loss: 0.013970
Training Iteration 368: Minibatch Loss: 0.013045
Training Iteration 369: Minibatch Loss: 0.013423
Training Iteration 370: Minibatch Loss: 0.014407
Training Iteration 371: Minibatch Loss: 0.012908
Training Iteration 372: Minibatch Loss: 0.013514
Training Iteration 373: Minibatch Loss: 0.012878
Training Iteration 374: Minibatch Loss: 0.012798
Training Iteration 375: Minibatch Loss: 0.014695
Training Iteration 376: Minibatch Loss: 0.013182
Training Iteration 377: Minibatch Loss: 0.012540
Training Iteration 378: Minibatch Loss: 0.012119
Training Iteration 379: Minibatch Loss: 0.013102
Training Iteration 380: Minibatch Loss: 0.012952
Training Iteration 381: Minibatch Loss: 0.012450
Training Iteration 382: Minibatch Loss: 0.012340
Training Iteration 383: Minibatch Loss: 0.012532
Training Iteration 384: Minibatch Loss: 0.012969
Training Iteration 385: Minibatch Loss: 0.012472
Training Iteration 386: Minibatch Loss: 0.012525
Training Iteration 387: Minibatch Loss: 0.013288
Training Iteration 388: Minibatch Loss: 0.012732
Training Iteration 389: Minibatch Loss: 0.012247
Training Iteration 390: Minibatch Loss: 0.012725
Training Iteration 391: Minibatch Loss: 0.012535
Training Iteration 392: Minibatch Loss: 0.013082
Training Iteration 393: Minibatch Loss: 0.012449
Training Iteration 394: Minibatch Loss: 0.012379
Training Iteration 395: Minibatch Loss: 0.012992
Training Iteration 396: Minibatch Loss: 0.011978
Training Iteration 397: Minibatch Loss: 0.013316
Training Iteration 398: Minibatch Loss: 0.012829
Training Iteration 399: Minibatch Loss: 0.011493
Training Iteration 400: Minibatch Loss: 0.013202
Training Iteration 401: Minibatch Loss: 0.012717
Training Iteration 402: Minibatch Loss: 0.011924
Training Iteration 403: Minibatch Loss: 0.012678
Training Iteration 404: Minibatch Loss: 0.012344
Training Iteration 405: Minibatch Loss: 0.012991
Training Iteration 406: Minibatch Loss: 0.013311
Training Iteration 407: Minibatch Loss: 0.011887
Training Iteration 408: Minibatch Loss: 0.012237
Training Iteration 409: Minibatch Loss: 0.011239
Training Iteration 410: Minibatch Loss: 0.012771
Training Iteration 411: Minibatch Loss: 0.011706
Training Iteration 412: Minibatch Loss: 0.012026
Training Iteration 413: Minibatch Loss: 0.012238
Training Iteration 414: Minibatch Loss: 0.012472
Training Iteration 415: Minibatch Loss: 0.012706
Training Iteration 416: Minibatch Loss: 0.012240
Training Iteration 417: Minibatch Loss: 0.012508
Training Iteration 418: Minibatch Loss: 0.013014
Training Iteration 419: Minibatch Loss: 0.012141
Training Iteration 420: Minibatch Loss: 0.012287
Training Iteration 421: Minibatch Loss: 0.012879
Training Iteration 422: Minibatch Loss: 0.013004
Training Iteration 423: Minibatch Loss: 0.013135
Training Iteration 424: Minibatch Loss: 0.010798
Training Iteration 425: Minibatch Loss: 0.012368
Training Iteration 426: Minibatch Loss: 0.011672
Training Iteration 427: Minibatch Loss: 0.011960
Training Iteration 428: Minibatch Loss: 0.012067
Training Iteration 429: Minibatch Loss: 0.013773
Training Iteration 430: Minibatch Loss: 0.012246
Training Iteration 431: Minibatch Loss: 0.013765
Training Iteration 432: Minibatch Loss: 0.012790
Training Iteration 433: Minibatch Loss: 0.010430
Training Iteration 434: Minibatch Loss: 0.011792
Training Iteration 435: Minibatch Loss: 0.012380
Training Iteration 436: Minibatch Loss: 0.011534
Training Iteration 437: Minibatch Loss: 0.012202
Training Iteration 438: Minibatch Loss: 0.012768
Training Iteration 439: Minibatch Loss: 0.012529
Training Iteration 440: Minibatch Loss: 0.012373
Training Iteration 441: Minibatch Loss: 0.012656
Training Iteration 442: Minibatch Loss: 0.011776
Training Iteration 443: Minibatch Loss: 0.012716
Training Iteration 444: Minibatch Loss: 0.012685
Training Iteration 445: Minibatch Loss: 0.011340
Training Iteration 446: Minibatch Loss: 0.011575
Training Iteration 447: Minibatch Loss: 0.011596
Training Iteration 448: Minibatch Loss: 0.012211
Training Iteration 449: Minibatch Loss: 0.013098
Test Loss: 0.012300
