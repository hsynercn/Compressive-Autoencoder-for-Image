Training Iteration 1: Minibatch Loss: 0.181674
Training Iteration 2: Minibatch Loss: 0.118406
Training Iteration 3: Minibatch Loss: 0.096931
Training Iteration 4: Minibatch Loss: 0.094852
Training Iteration 5: Minibatch Loss: 0.085822
Training Iteration 6: Minibatch Loss: 0.082480
Training Iteration 7: Minibatch Loss: 0.074413
Training Iteration 8: Minibatch Loss: 0.064785
Training Iteration 9: Minibatch Loss: 0.064001
Training Iteration 10: Minibatch Loss: 0.062367
Training Iteration 11: Minibatch Loss: 0.061277
Training Iteration 12: Minibatch Loss: 0.059456
Training Iteration 13: Minibatch Loss: 0.060822
Training Iteration 14: Minibatch Loss: 0.058597
Training Iteration 15: Minibatch Loss: 0.057190
Training Iteration 16: Minibatch Loss: 0.053947
Training Iteration 17: Minibatch Loss: 0.053208
Training Iteration 18: Minibatch Loss: 0.051722
Training Iteration 19: Minibatch Loss: 0.052158
Training Iteration 20: Minibatch Loss: 0.049994
Training Iteration 21: Minibatch Loss: 0.047995
Training Iteration 22: Minibatch Loss: 0.049925
Training Iteration 23: Minibatch Loss: 0.045900
Training Iteration 24: Minibatch Loss: 0.047156
Training Iteration 25: Minibatch Loss: 0.044548
Training Iteration 26: Minibatch Loss: 0.044918
Training Iteration 27: Minibatch Loss: 0.042228
Training Iteration 28: Minibatch Loss: 0.042499
Training Iteration 29: Minibatch Loss: 0.042166
Training Iteration 30: Minibatch Loss: 0.040944
Training Iteration 31: Minibatch Loss: 0.038624
Training Iteration 32: Minibatch Loss: 0.034848
Training Iteration 33: Minibatch Loss: 0.036808
Training Iteration 34: Minibatch Loss: 0.035538
Training Iteration 35: Minibatch Loss: 0.035447
Training Iteration 36: Minibatch Loss: 0.035479
Training Iteration 37: Minibatch Loss: 0.033672
Training Iteration 38: Minibatch Loss: 0.032948
Training Iteration 39: Minibatch Loss: 0.035073
Training Iteration 40: Minibatch Loss: 0.034485
Training Iteration 41: Minibatch Loss: 0.035571
Training Iteration 42: Minibatch Loss: 0.032009
Training Iteration 43: Minibatch Loss: 0.033289
Training Iteration 44: Minibatch Loss: 0.031192
Training Iteration 45: Minibatch Loss: 0.031725
Training Iteration 46: Minibatch Loss: 0.030097
Training Iteration 47: Minibatch Loss: 0.031448
Training Iteration 48: Minibatch Loss: 0.032071
Training Iteration 49: Minibatch Loss: 0.031755
Training Iteration 50: Minibatch Loss: 0.029161
Training Iteration 51: Minibatch Loss: 0.030459
Training Iteration 52: Minibatch Loss: 0.029815
Training Iteration 53: Minibatch Loss: 0.031243
Training Iteration 54: Minibatch Loss: 0.032176
Training Iteration 55: Minibatch Loss: 0.029951
Training Iteration 56: Minibatch Loss: 0.030362
Training Iteration 57: Minibatch Loss: 0.029848
Training Iteration 58: Minibatch Loss: 0.029448
Training Iteration 59: Minibatch Loss: 0.027892
Training Iteration 60: Minibatch Loss: 0.029456
Training Iteration 61: Minibatch Loss: 0.029024
Training Iteration 62: Minibatch Loss: 0.027138
Training Iteration 63: Minibatch Loss: 0.027895
Training Iteration 64: Minibatch Loss: 0.027518
Training Iteration 65: Minibatch Loss: 0.029639
Training Iteration 66: Minibatch Loss: 0.025932
Training Iteration 67: Minibatch Loss: 0.027530
Training Iteration 68: Minibatch Loss: 0.025415
Training Iteration 69: Minibatch Loss: 0.028123
Training Iteration 70: Minibatch Loss: 0.027697
Training Iteration 71: Minibatch Loss: 0.028217
Training Iteration 72: Minibatch Loss: 0.025999
Training Iteration 73: Minibatch Loss: 0.023842
Training Iteration 74: Minibatch Loss: 0.023187
Training Iteration 75: Minibatch Loss: 0.023780
Training Iteration 76: Minibatch Loss: 0.023863
Training Iteration 77: Minibatch Loss: 0.023608
Training Iteration 78: Minibatch Loss: 0.023895
Training Iteration 79: Minibatch Loss: 0.023926
Training Iteration 80: Minibatch Loss: 0.023392
Training Iteration 81: Minibatch Loss: 0.022555
Training Iteration 82: Minibatch Loss: 0.022343
Training Iteration 83: Minibatch Loss: 0.023101
Training Iteration 84: Minibatch Loss: 0.021742
Training Iteration 85: Minibatch Loss: 0.021588
Training Iteration 86: Minibatch Loss: 0.021811
Training Iteration 87: Minibatch Loss: 0.023583
Training Iteration 88: Minibatch Loss: 0.023168
Training Iteration 89: Minibatch Loss: 0.021557
Training Iteration 90: Minibatch Loss: 0.022002
Training Iteration 91: Minibatch Loss: 0.022118
Training Iteration 92: Minibatch Loss: 0.021813
Training Iteration 93: Minibatch Loss: 0.022617
Training Iteration 94: Minibatch Loss: 0.020891
Training Iteration 95: Minibatch Loss: 0.023180
Training Iteration 96: Minibatch Loss: 0.022457
Training Iteration 97: Minibatch Loss: 0.022379
Training Iteration 98: Minibatch Loss: 0.021343
Training Iteration 99: Minibatch Loss: 0.021744
Training Iteration 100: Minibatch Loss: 0.023343
Training Iteration 101: Minibatch Loss: 0.021116
Training Iteration 102: Minibatch Loss: 0.021242
Training Iteration 103: Minibatch Loss: 0.022501
Training Iteration 104: Minibatch Loss: 0.020087
Training Iteration 105: Minibatch Loss: 0.019304
Training Iteration 106: Minibatch Loss: 0.021318
Training Iteration 107: Minibatch Loss: 0.020261
Training Iteration 108: Minibatch Loss: 0.021802
Training Iteration 109: Minibatch Loss: 0.020748
Training Iteration 110: Minibatch Loss: 0.020721
Training Iteration 111: Minibatch Loss: 0.023028
Training Iteration 112: Minibatch Loss: 0.020457
Training Iteration 113: Minibatch Loss: 0.021437
Training Iteration 114: Minibatch Loss: 0.022551
Training Iteration 115: Minibatch Loss: 0.021121
Training Iteration 116: Minibatch Loss: 0.019341
Training Iteration 117: Minibatch Loss: 0.021848
Training Iteration 118: Minibatch Loss: 0.020348
Training Iteration 119: Minibatch Loss: 0.020789
Training Iteration 120: Minibatch Loss: 0.019693
Training Iteration 121: Minibatch Loss: 0.021206
Training Iteration 122: Minibatch Loss: 0.021647
Training Iteration 123: Minibatch Loss: 0.020199
Training Iteration 124: Minibatch Loss: 0.019556
Training Iteration 125: Minibatch Loss: 0.019789
Training Iteration 126: Minibatch Loss: 0.017434
Training Iteration 127: Minibatch Loss: 0.019449
Training Iteration 128: Minibatch Loss: 0.019005
Training Iteration 129: Minibatch Loss: 0.019044
Training Iteration 130: Minibatch Loss: 0.018902
Training Iteration 131: Minibatch Loss: 0.018543
Training Iteration 132: Minibatch Loss: 0.019123
Training Iteration 133: Minibatch Loss: 0.020678
Training Iteration 134: Minibatch Loss: 0.018578
Training Iteration 135: Minibatch Loss: 0.020070
Training Iteration 136: Minibatch Loss: 0.019834
Training Iteration 137: Minibatch Loss: 0.018656
Training Iteration 138: Minibatch Loss: 0.019722
Training Iteration 139: Minibatch Loss: 0.018521
Training Iteration 140: Minibatch Loss: 0.018149
Training Iteration 141: Minibatch Loss: 0.020540
Training Iteration 142: Minibatch Loss: 0.017541
Training Iteration 143: Minibatch Loss: 0.016894
Training Iteration 144: Minibatch Loss: 0.018033
Training Iteration 145: Minibatch Loss: 0.018449
Training Iteration 146: Minibatch Loss: 0.020571
Training Iteration 147: Minibatch Loss: 0.020060
Training Iteration 148: Minibatch Loss: 0.018943
Training Iteration 149: Minibatch Loss: 0.018184
Training Iteration 150: Minibatch Loss: 0.017889
Training Iteration 151: Minibatch Loss: 0.019744
Training Iteration 152: Minibatch Loss: 0.017559
Training Iteration 153: Minibatch Loss: 0.019389
Training Iteration 154: Minibatch Loss: 0.016527
Training Iteration 155: Minibatch Loss: 0.017003
Training Iteration 156: Minibatch Loss: 0.019278
Training Iteration 157: Minibatch Loss: 0.017940
Training Iteration 158: Minibatch Loss: 0.019100
Training Iteration 159: Minibatch Loss: 0.020372
Training Iteration 160: Minibatch Loss: 0.017351
Training Iteration 161: Minibatch Loss: 0.019757
Training Iteration 162: Minibatch Loss: 0.018577
Training Iteration 163: Minibatch Loss: 0.017788
Training Iteration 164: Minibatch Loss: 0.018218
Training Iteration 165: Minibatch Loss: 0.018917
Training Iteration 166: Minibatch Loss: 0.018898
Training Iteration 167: Minibatch Loss: 0.019074
Training Iteration 168: Minibatch Loss: 0.018486
Training Iteration 169: Minibatch Loss: 0.017466
Training Iteration 170: Minibatch Loss: 0.016471
Training Iteration 171: Minibatch Loss: 0.019968
Training Iteration 172: Minibatch Loss: 0.017625
Training Iteration 173: Minibatch Loss: 0.017706
Training Iteration 174: Minibatch Loss: 0.018656
Training Iteration 175: Minibatch Loss: 0.017567
Training Iteration 176: Minibatch Loss: 0.017374
Training Iteration 177: Minibatch Loss: 0.019752
Training Iteration 178: Minibatch Loss: 0.016850
Training Iteration 179: Minibatch Loss: 0.018558
Training Iteration 180: Minibatch Loss: 0.017907
Training Iteration 181: Minibatch Loss: 0.017848
Training Iteration 182: Minibatch Loss: 0.017889
Training Iteration 183: Minibatch Loss: 0.016758
Training Iteration 184: Minibatch Loss: 0.017588
Training Iteration 185: Minibatch Loss: 0.015830
Training Iteration 186: Minibatch Loss: 0.016551
Training Iteration 187: Minibatch Loss: 0.016971
Training Iteration 188: Minibatch Loss: 0.018982
Training Iteration 189: Minibatch Loss: 0.018000
Training Iteration 190: Minibatch Loss: 0.019051
Training Iteration 191: Minibatch Loss: 0.019202
Training Iteration 192: Minibatch Loss: 0.018079
Training Iteration 193: Minibatch Loss: 0.017923
Training Iteration 194: Minibatch Loss: 0.017022
Training Iteration 195: Minibatch Loss: 0.015931
Training Iteration 196: Minibatch Loss: 0.017801
Training Iteration 197: Minibatch Loss: 0.017113
Training Iteration 198: Minibatch Loss: 0.017032
Training Iteration 199: Minibatch Loss: 0.017300
Training Iteration 200: Minibatch Loss: 0.016862
Training Iteration 201: Minibatch Loss: 0.017617
Training Iteration 202: Minibatch Loss: 0.016859
Training Iteration 203: Minibatch Loss: 0.017775
Training Iteration 204: Minibatch Loss: 0.015189
Training Iteration 205: Minibatch Loss: 0.018029
Training Iteration 206: Minibatch Loss: 0.015906
Training Iteration 207: Minibatch Loss: 0.015298
Training Iteration 208: Minibatch Loss: 0.016642
Training Iteration 209: Minibatch Loss: 0.015609
Training Iteration 210: Minibatch Loss: 0.017105
Training Iteration 211: Minibatch Loss: 0.018274
Training Iteration 212: Minibatch Loss: 0.016016
Training Iteration 213: Minibatch Loss: 0.017112
Training Iteration 214: Minibatch Loss: 0.016056
Training Iteration 215: Minibatch Loss: 0.015463
Training Iteration 216: Minibatch Loss: 0.016660
Training Iteration 217: Minibatch Loss: 0.016936
Training Iteration 218: Minibatch Loss: 0.016434
Training Iteration 219: Minibatch Loss: 0.018517
Training Iteration 220: Minibatch Loss: 0.016357
Training Iteration 221: Minibatch Loss: 0.017291
Training Iteration 222: Minibatch Loss: 0.017347
Training Iteration 223: Minibatch Loss: 0.016290
Training Iteration 224: Minibatch Loss: 0.015077
Training Iteration 225: Minibatch Loss: 0.015155
Training Iteration 226: Minibatch Loss: 0.015725
Training Iteration 227: Minibatch Loss: 0.015845
Training Iteration 228: Minibatch Loss: 0.015785
Training Iteration 229: Minibatch Loss: 0.018429
Training Iteration 230: Minibatch Loss: 0.014880
Training Iteration 231: Minibatch Loss: 0.016601
Training Iteration 232: Minibatch Loss: 0.015248
Training Iteration 233: Minibatch Loss: 0.015482
Training Iteration 234: Minibatch Loss: 0.016020
Training Iteration 235: Minibatch Loss: 0.017644
Training Iteration 236: Minibatch Loss: 0.015551
Training Iteration 237: Minibatch Loss: 0.017460
Training Iteration 238: Minibatch Loss: 0.016211
Training Iteration 239: Minibatch Loss: 0.016835
Training Iteration 240: Minibatch Loss: 0.015178
Training Iteration 241: Minibatch Loss: 0.016385
Training Iteration 242: Minibatch Loss: 0.015250
Training Iteration 243: Minibatch Loss: 0.016707
Training Iteration 244: Minibatch Loss: 0.016848
Training Iteration 245: Minibatch Loss: 0.015805
Training Iteration 246: Minibatch Loss: 0.016923
Training Iteration 247: Minibatch Loss: 0.015032
Training Iteration 248: Minibatch Loss: 0.015583
Training Iteration 249: Minibatch Loss: 0.016033
Training Iteration 250: Minibatch Loss: 0.016258
Training Iteration 251: Minibatch Loss: 0.015243
Training Iteration 252: Minibatch Loss: 0.016187
Training Iteration 253: Minibatch Loss: 0.016692
Training Iteration 254: Minibatch Loss: 0.015992
Training Iteration 255: Minibatch Loss: 0.014467
Training Iteration 256: Minibatch Loss: 0.015522
Training Iteration 257: Minibatch Loss: 0.015737
Training Iteration 258: Minibatch Loss: 0.015665
Training Iteration 259: Minibatch Loss: 0.017422
Training Iteration 260: Minibatch Loss: 0.016892
Training Iteration 261: Minibatch Loss: 0.016036
Training Iteration 262: Minibatch Loss: 0.014401
Training Iteration 263: Minibatch Loss: 0.015647
Training Iteration 264: Minibatch Loss: 0.014606
Training Iteration 265: Minibatch Loss: 0.015598
Training Iteration 266: Minibatch Loss: 0.015547
Training Iteration 267: Minibatch Loss: 0.018056
Training Iteration 268: Minibatch Loss: 0.017276
Training Iteration 269: Minibatch Loss: 0.014202
Training Iteration 270: Minibatch Loss: 0.014130
Training Iteration 271: Minibatch Loss: 0.015826
Training Iteration 272: Minibatch Loss: 0.015682
Training Iteration 273: Minibatch Loss: 0.015339
Training Iteration 274: Minibatch Loss: 0.015447
Training Iteration 275: Minibatch Loss: 0.015381
Training Iteration 276: Minibatch Loss: 0.016527
Training Iteration 277: Minibatch Loss: 0.014335
Training Iteration 278: Minibatch Loss: 0.014511
Training Iteration 279: Minibatch Loss: 0.014735
Training Iteration 280: Minibatch Loss: 0.015589
Training Iteration 281: Minibatch Loss: 0.015397
Training Iteration 282: Minibatch Loss: 0.015383
Training Iteration 283: Minibatch Loss: 0.015563
Training Iteration 284: Minibatch Loss: 0.014841
Training Iteration 285: Minibatch Loss: 0.015304
Training Iteration 286: Minibatch Loss: 0.016513
Training Iteration 287: Minibatch Loss: 0.016507
Training Iteration 288: Minibatch Loss: 0.015257
Training Iteration 289: Minibatch Loss: 0.015324
Training Iteration 290: Minibatch Loss: 0.016773
Training Iteration 291: Minibatch Loss: 0.014819
Training Iteration 292: Minibatch Loss: 0.014446
Training Iteration 293: Minibatch Loss: 0.015140
Training Iteration 294: Minibatch Loss: 0.015257
Training Iteration 295: Minibatch Loss: 0.016256
Training Iteration 296: Minibatch Loss: 0.016098
Training Iteration 297: Minibatch Loss: 0.015539
Training Iteration 298: Minibatch Loss: 0.014061
Training Iteration 299: Minibatch Loss: 0.014767
Training Iteration 300: Minibatch Loss: 0.015657
Training Iteration 301: Minibatch Loss: 0.015028
Training Iteration 302: Minibatch Loss: 0.017707
Training Iteration 303: Minibatch Loss: 0.015396
Training Iteration 304: Minibatch Loss: 0.016058
Training Iteration 305: Minibatch Loss: 0.015206
Training Iteration 306: Minibatch Loss: 0.014478
Training Iteration 307: Minibatch Loss: 0.014577
Training Iteration 308: Minibatch Loss: 0.015893
Training Iteration 309: Minibatch Loss: 0.016041
Training Iteration 310: Minibatch Loss: 0.016831
Training Iteration 311: Minibatch Loss: 0.015183
Training Iteration 312: Minibatch Loss: 0.014997
Training Iteration 313: Minibatch Loss: 0.013704
Training Iteration 314: Minibatch Loss: 0.015805
Training Iteration 315: Minibatch Loss: 0.014859
Training Iteration 316: Minibatch Loss: 0.014552
Training Iteration 317: Minibatch Loss: 0.014678
Training Iteration 318: Minibatch Loss: 0.014668
Training Iteration 319: Minibatch Loss: 0.015596
Training Iteration 320: Minibatch Loss: 0.015863
Training Iteration 321: Minibatch Loss: 0.014587
Training Iteration 322: Minibatch Loss: 0.014505
Training Iteration 323: Minibatch Loss: 0.014104
Training Iteration 324: Minibatch Loss: 0.015360
Training Iteration 325: Minibatch Loss: 0.014027
Training Iteration 326: Minibatch Loss: 0.015539
Training Iteration 327: Minibatch Loss: 0.014863
Training Iteration 328: Minibatch Loss: 0.013356
Training Iteration 329: Minibatch Loss: 0.015047
Training Iteration 330: Minibatch Loss: 0.014469
Training Iteration 331: Minibatch Loss: 0.014315
Training Iteration 332: Minibatch Loss: 0.015440
Training Iteration 333: Minibatch Loss: 0.014281
Training Iteration 334: Minibatch Loss: 0.014115
Training Iteration 335: Minibatch Loss: 0.016112
Training Iteration 336: Minibatch Loss: 0.013150
Training Iteration 337: Minibatch Loss: 0.015533
Training Iteration 338: Minibatch Loss: 0.014548
Training Iteration 339: Minibatch Loss: 0.014453
Training Iteration 340: Minibatch Loss: 0.013294
Training Iteration 341: Minibatch Loss: 0.014668
Training Iteration 342: Minibatch Loss: 0.014773
Training Iteration 343: Minibatch Loss: 0.014375
Training Iteration 344: Minibatch Loss: 0.014485
Training Iteration 345: Minibatch Loss: 0.014306
Training Iteration 346: Minibatch Loss: 0.014120
Training Iteration 347: Minibatch Loss: 0.015002
Training Iteration 348: Minibatch Loss: 0.017015
Training Iteration 349: Minibatch Loss: 0.014950
Training Iteration 350: Minibatch Loss: 0.015302
Training Iteration 351: Minibatch Loss: 0.014130
Training Iteration 352: Minibatch Loss: 0.014469
Training Iteration 353: Minibatch Loss: 0.014576
Training Iteration 354: Minibatch Loss: 0.013458
Training Iteration 355: Minibatch Loss: 0.015805
Training Iteration 356: Minibatch Loss: 0.014314
Training Iteration 357: Minibatch Loss: 0.016028
Training Iteration 358: Minibatch Loss: 0.013112
Training Iteration 359: Minibatch Loss: 0.014789
Training Iteration 360: Minibatch Loss: 0.013934
Training Iteration 361: Minibatch Loss: 0.013877
Training Iteration 362: Minibatch Loss: 0.014433
Training Iteration 363: Minibatch Loss: 0.013546
Training Iteration 364: Minibatch Loss: 0.013474
Training Iteration 365: Minibatch Loss: 0.014085
Training Iteration 366: Minibatch Loss: 0.014519
Training Iteration 367: Minibatch Loss: 0.015316
Training Iteration 368: Minibatch Loss: 0.012677
Training Iteration 369: Minibatch Loss: 0.014968
Training Iteration 370: Minibatch Loss: 0.013329
Training Iteration 371: Minibatch Loss: 0.015875
Training Iteration 372: Minibatch Loss: 0.014387
Training Iteration 373: Minibatch Loss: 0.015379
Training Iteration 374: Minibatch Loss: 0.014958
Training Iteration 375: Minibatch Loss: 0.013466
Training Iteration 376: Minibatch Loss: 0.015137
Training Iteration 377: Minibatch Loss: 0.013915
Training Iteration 378: Minibatch Loss: 0.014614
Training Iteration 379: Minibatch Loss: 0.015334
Training Iteration 380: Minibatch Loss: 0.015348
Training Iteration 381: Minibatch Loss: 0.013608
Training Iteration 382: Minibatch Loss: 0.014190
Training Iteration 383: Minibatch Loss: 0.013179
Training Iteration 384: Minibatch Loss: 0.014064
Training Iteration 385: Minibatch Loss: 0.013839
Training Iteration 386: Minibatch Loss: 0.013747
Training Iteration 387: Minibatch Loss: 0.013578
Training Iteration 388: Minibatch Loss: 0.012995
Training Iteration 389: Minibatch Loss: 0.015112
Training Iteration 390: Minibatch Loss: 0.013952
Training Iteration 391: Minibatch Loss: 0.014965
Training Iteration 392: Minibatch Loss: 0.013183
Training Iteration 393: Minibatch Loss: 0.013505
Training Iteration 394: Minibatch Loss: 0.013698
Training Iteration 395: Minibatch Loss: 0.013620
Training Iteration 396: Minibatch Loss: 0.013499
Training Iteration 397: Minibatch Loss: 0.012904
Training Iteration 398: Minibatch Loss: 0.014179
Training Iteration 399: Minibatch Loss: 0.013476
Training Iteration 400: Minibatch Loss: 0.012999
Training Iteration 401: Minibatch Loss: 0.013985
Training Iteration 402: Minibatch Loss: 0.013768
Training Iteration 403: Minibatch Loss: 0.013629
Training Iteration 404: Minibatch Loss: 0.013922
Training Iteration 405: Minibatch Loss: 0.014476
Training Iteration 406: Minibatch Loss: 0.012537
Training Iteration 407: Minibatch Loss: 0.012917
Training Iteration 408: Minibatch Loss: 0.012871
Training Iteration 409: Minibatch Loss: 0.013636
Training Iteration 410: Minibatch Loss: 0.013110
Training Iteration 411: Minibatch Loss: 0.012629
Training Iteration 412: Minibatch Loss: 0.014007
Training Iteration 413: Minibatch Loss: 0.013386
Training Iteration 414: Minibatch Loss: 0.013759
Training Iteration 415: Minibatch Loss: 0.013439
Training Iteration 416: Minibatch Loss: 0.015286
Training Iteration 417: Minibatch Loss: 0.013841
Training Iteration 418: Minibatch Loss: 0.013232
Training Iteration 419: Minibatch Loss: 0.013761
Training Iteration 420: Minibatch Loss: 0.012993
Training Iteration 421: Minibatch Loss: 0.012512
Training Iteration 422: Minibatch Loss: 0.013361
Training Iteration 423: Minibatch Loss: 0.014509
Training Iteration 424: Minibatch Loss: 0.013437
Training Iteration 425: Minibatch Loss: 0.014337
Training Iteration 426: Minibatch Loss: 0.014095
Training Iteration 427: Minibatch Loss: 0.012476
Training Iteration 428: Minibatch Loss: 0.013227
Training Iteration 429: Minibatch Loss: 0.012489
Training Iteration 430: Minibatch Loss: 0.012627
Training Iteration 431: Minibatch Loss: 0.013326
Training Iteration 432: Minibatch Loss: 0.011964
Training Iteration 433: Minibatch Loss: 0.012615
Training Iteration 434: Minibatch Loss: 0.013213
Training Iteration 435: Minibatch Loss: 0.012574
Training Iteration 436: Minibatch Loss: 0.012359
Training Iteration 437: Minibatch Loss: 0.013681
Training Iteration 438: Minibatch Loss: 0.012994
Training Iteration 439: Minibatch Loss: 0.013157
Training Iteration 440: Minibatch Loss: 0.012550
Training Iteration 441: Minibatch Loss: 0.013332
Training Iteration 442: Minibatch Loss: 0.013709
Training Iteration 443: Minibatch Loss: 0.012667
Training Iteration 444: Minibatch Loss: 0.013804
Training Iteration 445: Minibatch Loss: 0.012929
Training Iteration 446: Minibatch Loss: 0.012458
Training Iteration 447: Minibatch Loss: 0.012999
Training Iteration 448: Minibatch Loss: 0.012597
Training Iteration 449: Minibatch Loss: 0.013428
Test Loss: 0.013244
