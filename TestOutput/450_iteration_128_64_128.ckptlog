Training Iteration 1: Minibatch Loss: 0.205832
Training Iteration 2: Minibatch Loss: 0.140892
Training Iteration 3: Minibatch Loss: 0.120492
Training Iteration 4: Minibatch Loss: 0.107480
Training Iteration 5: Minibatch Loss: 0.098409
Training Iteration 6: Minibatch Loss: 0.096220
Training Iteration 7: Minibatch Loss: 0.090667
Training Iteration 8: Minibatch Loss: 0.088113
Training Iteration 9: Minibatch Loss: 0.084121
Training Iteration 10: Minibatch Loss: 0.080728
Training Iteration 11: Minibatch Loss: 0.077362
Training Iteration 12: Minibatch Loss: 0.075278
Training Iteration 13: Minibatch Loss: 0.072803
Training Iteration 14: Minibatch Loss: 0.070828
Training Iteration 15: Minibatch Loss: 0.069948
Training Iteration 16: Minibatch Loss: 0.067728
Training Iteration 17: Minibatch Loss: 0.068637
Training Iteration 18: Minibatch Loss: 0.066031
Training Iteration 19: Minibatch Loss: 0.067985
Training Iteration 20: Minibatch Loss: 0.064279
Training Iteration 21: Minibatch Loss: 0.062493
Training Iteration 22: Minibatch Loss: 0.061844
Training Iteration 23: Minibatch Loss: 0.061603
Training Iteration 24: Minibatch Loss: 0.060201
Training Iteration 25: Minibatch Loss: 0.058807
Training Iteration 26: Minibatch Loss: 0.059449
Training Iteration 27: Minibatch Loss: 0.058834
Training Iteration 28: Minibatch Loss: 0.057524
Training Iteration 29: Minibatch Loss: 0.055928
Training Iteration 30: Minibatch Loss: 0.052543
Training Iteration 31: Minibatch Loss: 0.052987
Training Iteration 32: Minibatch Loss: 0.050379
Training Iteration 33: Minibatch Loss: 0.049156
Training Iteration 34: Minibatch Loss: 0.048415
Training Iteration 35: Minibatch Loss: 0.050183
Training Iteration 36: Minibatch Loss: 0.050229
Training Iteration 37: Minibatch Loss: 0.048636
Training Iteration 38: Minibatch Loss: 0.048410
Training Iteration 39: Minibatch Loss: 0.043464
Training Iteration 40: Minibatch Loss: 0.045917
Training Iteration 41: Minibatch Loss: 0.045967
Training Iteration 42: Minibatch Loss: 0.045978
Training Iteration 43: Minibatch Loss: 0.042204
Training Iteration 44: Minibatch Loss: 0.044393
Training Iteration 45: Minibatch Loss: 0.040297
Training Iteration 46: Minibatch Loss: 0.042341
Training Iteration 47: Minibatch Loss: 0.040809
Training Iteration 48: Minibatch Loss: 0.040302
Training Iteration 49: Minibatch Loss: 0.041014
Training Iteration 50: Minibatch Loss: 0.040982
Training Iteration 51: Minibatch Loss: 0.038689
Training Iteration 52: Minibatch Loss: 0.039738
Training Iteration 53: Minibatch Loss: 0.037807
Training Iteration 54: Minibatch Loss: 0.037483
Training Iteration 55: Minibatch Loss: 0.037971
Training Iteration 56: Minibatch Loss: 0.038973
Training Iteration 57: Minibatch Loss: 0.037462
Training Iteration 58: Minibatch Loss: 0.038835
Training Iteration 59: Minibatch Loss: 0.038061
Training Iteration 60: Minibatch Loss: 0.036656
Training Iteration 61: Minibatch Loss: 0.038943
Training Iteration 62: Minibatch Loss: 0.038193
Training Iteration 63: Minibatch Loss: 0.038012
Training Iteration 64: Minibatch Loss: 0.037652
Training Iteration 65: Minibatch Loss: 0.036395
Training Iteration 66: Minibatch Loss: 0.036889
Training Iteration 67: Minibatch Loss: 0.035446
Training Iteration 68: Minibatch Loss: 0.034436
Training Iteration 69: Minibatch Loss: 0.035123
Training Iteration 70: Minibatch Loss: 0.035292
Training Iteration 71: Minibatch Loss: 0.035190
Training Iteration 72: Minibatch Loss: 0.034493
Training Iteration 73: Minibatch Loss: 0.032856
Training Iteration 74: Minibatch Loss: 0.034185
Training Iteration 75: Minibatch Loss: 0.033161
Training Iteration 76: Minibatch Loss: 0.032395
Training Iteration 77: Minibatch Loss: 0.032585
Training Iteration 78: Minibatch Loss: 0.032073
Training Iteration 79: Minibatch Loss: 0.033226
Training Iteration 80: Minibatch Loss: 0.032826
Training Iteration 81: Minibatch Loss: 0.033584
Training Iteration 82: Minibatch Loss: 0.029760
Training Iteration 83: Minibatch Loss: 0.031032
Training Iteration 84: Minibatch Loss: 0.030774
Training Iteration 85: Minibatch Loss: 0.031259
Training Iteration 86: Minibatch Loss: 0.031174
Training Iteration 87: Minibatch Loss: 0.031039
Training Iteration 88: Minibatch Loss: 0.030077
Training Iteration 89: Minibatch Loss: 0.030015
Training Iteration 90: Minibatch Loss: 0.029383
Training Iteration 91: Minibatch Loss: 0.029499
Training Iteration 92: Minibatch Loss: 0.029497
Training Iteration 93: Minibatch Loss: 0.029282
Training Iteration 94: Minibatch Loss: 0.028971
Training Iteration 95: Minibatch Loss: 0.028551
Training Iteration 96: Minibatch Loss: 0.027343
Training Iteration 97: Minibatch Loss: 0.029136
Training Iteration 98: Minibatch Loss: 0.029502
Training Iteration 99: Minibatch Loss: 0.030369
Training Iteration 100: Minibatch Loss: 0.028847
Training Iteration 101: Minibatch Loss: 0.029481
Training Iteration 102: Minibatch Loss: 0.029988
Training Iteration 103: Minibatch Loss: 0.028733
Training Iteration 104: Minibatch Loss: 0.027740
Training Iteration 105: Minibatch Loss: 0.030117
Training Iteration 106: Minibatch Loss: 0.028816
Training Iteration 107: Minibatch Loss: 0.027762
Training Iteration 108: Minibatch Loss: 0.028302
Training Iteration 109: Minibatch Loss: 0.027473
Training Iteration 110: Minibatch Loss: 0.028601
Training Iteration 111: Minibatch Loss: 0.027912
Training Iteration 112: Minibatch Loss: 0.026952
Training Iteration 113: Minibatch Loss: 0.027674
Training Iteration 114: Minibatch Loss: 0.027066
Training Iteration 115: Minibatch Loss: 0.029026
Training Iteration 116: Minibatch Loss: 0.028001
Training Iteration 117: Minibatch Loss: 0.027348
Training Iteration 118: Minibatch Loss: 0.027218
Training Iteration 119: Minibatch Loss: 0.028836
Training Iteration 120: Minibatch Loss: 0.026215
Training Iteration 121: Minibatch Loss: 0.027204
Training Iteration 122: Minibatch Loss: 0.028077
Training Iteration 123: Minibatch Loss: 0.027539
Training Iteration 124: Minibatch Loss: 0.027230
Training Iteration 125: Minibatch Loss: 0.027714
Training Iteration 126: Minibatch Loss: 0.027223
Training Iteration 127: Minibatch Loss: 0.027024
Training Iteration 128: Minibatch Loss: 0.027196
Training Iteration 129: Minibatch Loss: 0.028223
Training Iteration 130: Minibatch Loss: 0.026347
Training Iteration 131: Minibatch Loss: 0.029595
Training Iteration 132: Minibatch Loss: 0.027508
Training Iteration 133: Minibatch Loss: 0.026400
Training Iteration 134: Minibatch Loss: 0.026426
Training Iteration 135: Minibatch Loss: 0.026932
Training Iteration 136: Minibatch Loss: 0.025866
Training Iteration 137: Minibatch Loss: 0.025464
Training Iteration 138: Minibatch Loss: 0.025455
Training Iteration 139: Minibatch Loss: 0.026097
Training Iteration 140: Minibatch Loss: 0.025537
Training Iteration 141: Minibatch Loss: 0.025045
Training Iteration 142: Minibatch Loss: 0.023546
Training Iteration 143: Minibatch Loss: 0.023685
Training Iteration 144: Minibatch Loss: 0.024442
Training Iteration 145: Minibatch Loss: 0.024843
Training Iteration 146: Minibatch Loss: 0.024723
Training Iteration 147: Minibatch Loss: 0.023457
Training Iteration 148: Minibatch Loss: 0.025015
Training Iteration 149: Minibatch Loss: 0.023812
Training Iteration 150: Minibatch Loss: 0.023622
Training Iteration 151: Minibatch Loss: 0.022630
Training Iteration 152: Minibatch Loss: 0.024036
Training Iteration 153: Minibatch Loss: 0.022593
Training Iteration 154: Minibatch Loss: 0.023479
Training Iteration 155: Minibatch Loss: 0.024150
Training Iteration 156: Minibatch Loss: 0.023484
Training Iteration 157: Minibatch Loss: 0.023262
Training Iteration 158: Minibatch Loss: 0.023779
Training Iteration 159: Minibatch Loss: 0.024123
Training Iteration 160: Minibatch Loss: 0.022658
Training Iteration 161: Minibatch Loss: 0.023268
Training Iteration 162: Minibatch Loss: 0.022355
Training Iteration 163: Minibatch Loss: 0.023968
Training Iteration 164: Minibatch Loss: 0.022834
Training Iteration 165: Minibatch Loss: 0.024391
Training Iteration 166: Minibatch Loss: 0.022188
Training Iteration 167: Minibatch Loss: 0.021393
Training Iteration 168: Minibatch Loss: 0.021213
Training Iteration 169: Minibatch Loss: 0.022456
Training Iteration 170: Minibatch Loss: 0.021442
Training Iteration 171: Minibatch Loss: 0.022125
Training Iteration 172: Minibatch Loss: 0.021655
Training Iteration 173: Minibatch Loss: 0.021919
Training Iteration 174: Minibatch Loss: 0.021917
Training Iteration 175: Minibatch Loss: 0.022439
Training Iteration 176: Minibatch Loss: 0.021172
Training Iteration 177: Minibatch Loss: 0.020774
Training Iteration 178: Minibatch Loss: 0.021229
Training Iteration 179: Minibatch Loss: 0.021832
Training Iteration 180: Minibatch Loss: 0.021985
Training Iteration 181: Minibatch Loss: 0.021234
Training Iteration 182: Minibatch Loss: 0.021721
Training Iteration 183: Minibatch Loss: 0.022005
Training Iteration 184: Minibatch Loss: 0.022203
Training Iteration 185: Minibatch Loss: 0.021996
Training Iteration 186: Minibatch Loss: 0.021204
Training Iteration 187: Minibatch Loss: 0.021548
Training Iteration 188: Minibatch Loss: 0.021458
Training Iteration 189: Minibatch Loss: 0.021882
Training Iteration 190: Minibatch Loss: 0.021177
Training Iteration 191: Minibatch Loss: 0.021627
Training Iteration 192: Minibatch Loss: 0.020593
Training Iteration 193: Minibatch Loss: 0.020492
Training Iteration 194: Minibatch Loss: 0.020407
Training Iteration 195: Minibatch Loss: 0.021294
Training Iteration 196: Minibatch Loss: 0.020525
Training Iteration 197: Minibatch Loss: 0.019653
Training Iteration 198: Minibatch Loss: 0.018639
Training Iteration 199: Minibatch Loss: 0.019138
Training Iteration 200: Minibatch Loss: 0.019805
Training Iteration 201: Minibatch Loss: 0.020388
Training Iteration 202: Minibatch Loss: 0.020485
Training Iteration 203: Minibatch Loss: 0.019117
Training Iteration 204: Minibatch Loss: 0.018270
Training Iteration 205: Minibatch Loss: 0.019195
Training Iteration 206: Minibatch Loss: 0.018080
Training Iteration 207: Minibatch Loss: 0.018401
Training Iteration 208: Minibatch Loss: 0.018200
Training Iteration 209: Minibatch Loss: 0.018354
Training Iteration 210: Minibatch Loss: 0.018562
Training Iteration 211: Minibatch Loss: 0.020542
Training Iteration 212: Minibatch Loss: 0.019121
Training Iteration 213: Minibatch Loss: 0.017830
Training Iteration 214: Minibatch Loss: 0.018369
Training Iteration 215: Minibatch Loss: 0.018625
Training Iteration 216: Minibatch Loss: 0.019125
Training Iteration 217: Minibatch Loss: 0.017699
Training Iteration 218: Minibatch Loss: 0.018029
Training Iteration 219: Minibatch Loss: 0.019120
Training Iteration 220: Minibatch Loss: 0.016959
Training Iteration 221: Minibatch Loss: 0.018548
Training Iteration 222: Minibatch Loss: 0.018215
Training Iteration 223: Minibatch Loss: 0.018580
Training Iteration 224: Minibatch Loss: 0.017475
Training Iteration 225: Minibatch Loss: 0.018306
Training Iteration 226: Minibatch Loss: 0.016582
Training Iteration 227: Minibatch Loss: 0.018369
Training Iteration 228: Minibatch Loss: 0.019485
Training Iteration 229: Minibatch Loss: 0.017002
Training Iteration 230: Minibatch Loss: 0.017935
Training Iteration 231: Minibatch Loss: 0.017639
Training Iteration 232: Minibatch Loss: 0.018165
Training Iteration 233: Minibatch Loss: 0.016663
Training Iteration 234: Minibatch Loss: 0.018181
Training Iteration 235: Minibatch Loss: 0.017604
Training Iteration 236: Minibatch Loss: 0.018020
Training Iteration 237: Minibatch Loss: 0.016508
Training Iteration 238: Minibatch Loss: 0.018117
Training Iteration 239: Minibatch Loss: 0.017684
Training Iteration 240: Minibatch Loss: 0.018593
Training Iteration 241: Minibatch Loss: 0.018639
Training Iteration 242: Minibatch Loss: 0.016957
Training Iteration 243: Minibatch Loss: 0.017389
Training Iteration 244: Minibatch Loss: 0.018366
Training Iteration 245: Minibatch Loss: 0.016853
Training Iteration 246: Minibatch Loss: 0.016984
Training Iteration 247: Minibatch Loss: 0.017747
Training Iteration 248: Minibatch Loss: 0.017207
Training Iteration 249: Minibatch Loss: 0.016433
Training Iteration 250: Minibatch Loss: 0.016809
Training Iteration 251: Minibatch Loss: 0.017502
Training Iteration 252: Minibatch Loss: 0.017253
Training Iteration 253: Minibatch Loss: 0.015807
Training Iteration 254: Minibatch Loss: 0.015995
Training Iteration 255: Minibatch Loss: 0.016560
Training Iteration 256: Minibatch Loss: 0.015005
Training Iteration 257: Minibatch Loss: 0.015021
Training Iteration 258: Minibatch Loss: 0.015917
Training Iteration 259: Minibatch Loss: 0.014932
Training Iteration 260: Minibatch Loss: 0.014832
Training Iteration 261: Minibatch Loss: 0.015641
Training Iteration 262: Minibatch Loss: 0.014037
Training Iteration 263: Minibatch Loss: 0.015951
Training Iteration 264: Minibatch Loss: 0.015484
Training Iteration 265: Minibatch Loss: 0.016037
Training Iteration 266: Minibatch Loss: 0.014042
Training Iteration 267: Minibatch Loss: 0.014820
Training Iteration 268: Minibatch Loss: 0.015284
Training Iteration 269: Minibatch Loss: 0.015325
Training Iteration 270: Minibatch Loss: 0.016205
Training Iteration 271: Minibatch Loss: 0.016410
Training Iteration 272: Minibatch Loss: 0.014833
Training Iteration 273: Minibatch Loss: 0.016275
Training Iteration 274: Minibatch Loss: 0.015891
Training Iteration 275: Minibatch Loss: 0.014184
Training Iteration 276: Minibatch Loss: 0.012991
Training Iteration 277: Minibatch Loss: 0.013970
Training Iteration 278: Minibatch Loss: 0.014262
Training Iteration 279: Minibatch Loss: 0.014094
Training Iteration 280: Minibatch Loss: 0.015142
Training Iteration 281: Minibatch Loss: 0.013680
Training Iteration 282: Minibatch Loss: 0.013141
Training Iteration 283: Minibatch Loss: 0.013235
Training Iteration 284: Minibatch Loss: 0.012794
Training Iteration 285: Minibatch Loss: 0.013887
Training Iteration 286: Minibatch Loss: 0.013776
Training Iteration 287: Minibatch Loss: 0.013909
Training Iteration 288: Minibatch Loss: 0.012936
Training Iteration 289: Minibatch Loss: 0.013358
Training Iteration 290: Minibatch Loss: 0.013530
Training Iteration 291: Minibatch Loss: 0.013333
Training Iteration 292: Minibatch Loss: 0.014129
Training Iteration 293: Minibatch Loss: 0.012735
Training Iteration 294: Minibatch Loss: 0.013401
Training Iteration 295: Minibatch Loss: 0.014104
Training Iteration 296: Minibatch Loss: 0.013572
Training Iteration 297: Minibatch Loss: 0.012895
Training Iteration 298: Minibatch Loss: 0.013518
Training Iteration 299: Minibatch Loss: 0.012936
Training Iteration 300: Minibatch Loss: 0.013200
Training Iteration 301: Minibatch Loss: 0.014051
Training Iteration 302: Minibatch Loss: 0.013718
Training Iteration 303: Minibatch Loss: 0.012773
Training Iteration 304: Minibatch Loss: 0.013383
Training Iteration 305: Minibatch Loss: 0.013063
Training Iteration 306: Minibatch Loss: 0.012894
Training Iteration 307: Minibatch Loss: 0.013485
Training Iteration 308: Minibatch Loss: 0.013330
Training Iteration 309: Minibatch Loss: 0.012474
Training Iteration 310: Minibatch Loss: 0.012645
Training Iteration 311: Minibatch Loss: 0.013269
Training Iteration 312: Minibatch Loss: 0.012843
Training Iteration 313: Minibatch Loss: 0.012209
Training Iteration 314: Minibatch Loss: 0.013201
Training Iteration 315: Minibatch Loss: 0.012451
Training Iteration 316: Minibatch Loss: 0.012817
Training Iteration 317: Minibatch Loss: 0.013621
Training Iteration 318: Minibatch Loss: 0.012690
Training Iteration 319: Minibatch Loss: 0.012312
Training Iteration 320: Minibatch Loss: 0.012725
Training Iteration 321: Minibatch Loss: 0.012582
Training Iteration 322: Minibatch Loss: 0.012463
Training Iteration 323: Minibatch Loss: 0.012029
Training Iteration 324: Minibatch Loss: 0.012131
Training Iteration 325: Minibatch Loss: 0.014031
Training Iteration 326: Minibatch Loss: 0.011610
Training Iteration 327: Minibatch Loss: 0.012817
Training Iteration 328: Minibatch Loss: 0.012372
Training Iteration 329: Minibatch Loss: 0.012026
Training Iteration 330: Minibatch Loss: 0.012080
Training Iteration 331: Minibatch Loss: 0.011591
Training Iteration 332: Minibatch Loss: 0.012848
Training Iteration 333: Minibatch Loss: 0.013305
Training Iteration 334: Minibatch Loss: 0.013975
Training Iteration 335: Minibatch Loss: 0.012899
Training Iteration 336: Minibatch Loss: 0.012258
Training Iteration 337: Minibatch Loss: 0.012022
Training Iteration 338: Minibatch Loss: 0.011998
Training Iteration 339: Minibatch Loss: 0.011344
Training Iteration 340: Minibatch Loss: 0.011641
Training Iteration 341: Minibatch Loss: 0.011685
Training Iteration 342: Minibatch Loss: 0.011413
Training Iteration 343: Minibatch Loss: 0.012401
Training Iteration 344: Minibatch Loss: 0.012323
Training Iteration 345: Minibatch Loss: 0.011801
Training Iteration 346: Minibatch Loss: 0.012094
Training Iteration 347: Minibatch Loss: 0.012211
Training Iteration 348: Minibatch Loss: 0.013024
Training Iteration 349: Minibatch Loss: 0.012355
Training Iteration 350: Minibatch Loss: 0.012661
Training Iteration 351: Minibatch Loss: 0.013153
Training Iteration 352: Minibatch Loss: 0.012456
Training Iteration 353: Minibatch Loss: 0.012322
Training Iteration 354: Minibatch Loss: 0.011920
Training Iteration 355: Minibatch Loss: 0.012200
Training Iteration 356: Minibatch Loss: 0.012145
Training Iteration 357: Minibatch Loss: 0.012244
Training Iteration 358: Minibatch Loss: 0.011388
Training Iteration 359: Minibatch Loss: 0.011385
Training Iteration 360: Minibatch Loss: 0.012667
Training Iteration 361: Minibatch Loss: 0.012063
Training Iteration 362: Minibatch Loss: 0.012891
Training Iteration 363: Minibatch Loss: 0.012707
Training Iteration 364: Minibatch Loss: 0.013710
Training Iteration 365: Minibatch Loss: 0.013844
Training Iteration 366: Minibatch Loss: 0.012355
Training Iteration 367: Minibatch Loss: 0.012216
Training Iteration 368: Minibatch Loss: 0.011653
Training Iteration 369: Minibatch Loss: 0.011921
Training Iteration 370: Minibatch Loss: 0.012433
Training Iteration 371: Minibatch Loss: 0.012023
Training Iteration 372: Minibatch Loss: 0.011648
Training Iteration 373: Minibatch Loss: 0.012052
Training Iteration 374: Minibatch Loss: 0.011783
Training Iteration 375: Minibatch Loss: 0.012445
Training Iteration 376: Minibatch Loss: 0.013165
Training Iteration 377: Minibatch Loss: 0.012368
Training Iteration 378: Minibatch Loss: 0.011626
Training Iteration 379: Minibatch Loss: 0.013110
Training Iteration 380: Minibatch Loss: 0.013108
Training Iteration 381: Minibatch Loss: 0.011462
Training Iteration 382: Minibatch Loss: 0.013066
Training Iteration 383: Minibatch Loss: 0.011919
Training Iteration 384: Minibatch Loss: 0.012021
Training Iteration 385: Minibatch Loss: 0.011408
Training Iteration 386: Minibatch Loss: 0.012596
Training Iteration 387: Minibatch Loss: 0.012119
Training Iteration 388: Minibatch Loss: 0.010757
Training Iteration 389: Minibatch Loss: 0.011877
Training Iteration 390: Minibatch Loss: 0.012163
Training Iteration 391: Minibatch Loss: 0.012437
Training Iteration 392: Minibatch Loss: 0.011299
Training Iteration 393: Minibatch Loss: 0.011797
Training Iteration 394: Minibatch Loss: 0.011601
Training Iteration 395: Minibatch Loss: 0.011862
Training Iteration 396: Minibatch Loss: 0.011438
Training Iteration 397: Minibatch Loss: 0.012249
Training Iteration 398: Minibatch Loss: 0.011850
Training Iteration 399: Minibatch Loss: 0.012765
Training Iteration 400: Minibatch Loss: 0.011766
Training Iteration 401: Minibatch Loss: 0.012340
Training Iteration 402: Minibatch Loss: 0.011975
Training Iteration 403: Minibatch Loss: 0.010852
Training Iteration 404: Minibatch Loss: 0.010815
Training Iteration 405: Minibatch Loss: 0.011036
Training Iteration 406: Minibatch Loss: 0.011611
Training Iteration 407: Minibatch Loss: 0.012186
Training Iteration 408: Minibatch Loss: 0.012281
Training Iteration 409: Minibatch Loss: 0.011944
Training Iteration 410: Minibatch Loss: 0.011033
Training Iteration 411: Minibatch Loss: 0.011028
Training Iteration 412: Minibatch Loss: 0.010405
Training Iteration 413: Minibatch Loss: 0.012328
Training Iteration 414: Minibatch Loss: 0.012229
Training Iteration 415: Minibatch Loss: 0.012137
Training Iteration 416: Minibatch Loss: 0.012406
Training Iteration 417: Minibatch Loss: 0.011125
Training Iteration 418: Minibatch Loss: 0.011980
Training Iteration 419: Minibatch Loss: 0.011876
Training Iteration 420: Minibatch Loss: 0.011156
Training Iteration 421: Minibatch Loss: 0.011647
Training Iteration 422: Minibatch Loss: 0.010644
Training Iteration 423: Minibatch Loss: 0.010910
Training Iteration 424: Minibatch Loss: 0.010781
Training Iteration 425: Minibatch Loss: 0.011363
Training Iteration 426: Minibatch Loss: 0.010675
Training Iteration 427: Minibatch Loss: 0.011382
Training Iteration 428: Minibatch Loss: 0.011106
Training Iteration 429: Minibatch Loss: 0.010189
Training Iteration 430: Minibatch Loss: 0.011280
Training Iteration 431: Minibatch Loss: 0.010894
Training Iteration 432: Minibatch Loss: 0.011126
Training Iteration 433: Minibatch Loss: 0.011625
Training Iteration 434: Minibatch Loss: 0.011386
Training Iteration 435: Minibatch Loss: 0.011167
Training Iteration 436: Minibatch Loss: 0.011232
Training Iteration 437: Minibatch Loss: 0.010030
Training Iteration 438: Minibatch Loss: 0.012469
Training Iteration 439: Minibatch Loss: 0.011159
Training Iteration 440: Minibatch Loss: 0.011565
Training Iteration 441: Minibatch Loss: 0.011209
Training Iteration 442: Minibatch Loss: 0.010372
Training Iteration 443: Minibatch Loss: 0.011437
Training Iteration 444: Minibatch Loss: 0.011781
Training Iteration 445: Minibatch Loss: 0.011112
Training Iteration 446: Minibatch Loss: 0.010926
Training Iteration 447: Minibatch Loss: 0.011281
Training Iteration 448: Minibatch Loss: 0.010351
Training Iteration 449: Minibatch Loss: 0.011760
Test Loss: 0.011173
